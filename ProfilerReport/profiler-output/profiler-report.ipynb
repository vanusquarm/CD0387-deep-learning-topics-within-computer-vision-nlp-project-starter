{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018266,
     "end_time": "2022-01-20T11:12:56.370508",
     "exception": false,
     "start_time": "2022-01-20T11:12:56.352242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SageMaker Debugger Profiling Report\n",
    "\n",
    "SageMaker Debugger auto generated this report. You can generate similar reports on all supported training jobs. The report provides summary of training job, system resource usage statistics, framework metrics, rules summary, and detailed analysis from each rule. The graphs and tables are interactive. \n",
    "\n",
    "**Legal disclaimer:** This report and any recommendations are provided for informational purposes only and are not definitive. You are responsible for making your own independent assessment of the information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:56.413172Z",
     "iopub.status.busy": "2022-01-20T11:12:56.412661Z",
     "iopub.status.idle": "2022-01-20T11:12:56.986887Z",
     "shell.execute_reply": "2022-01-20T11:12:56.987312Z"
    },
    "papermill": {
     "duration": 0.599626,
     "end_time": "2022-01-20T11:12:56.987523",
     "exception": false,
     "start_time": "2022-01-20T11:12:56.387897",
     "status": "completed"
    },
    "tags": [
     "hide-output",
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-20 11:12:56.980 ip-10-2-222-95.ec2.internal:731 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: /opt/ml/processing/input/profiler/signals/ProfilerReport\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from smdebug.profiler.utils import us_since_epoch_to_human_readable_time, ns_since_epoch_to_human_readable_time\n",
    "from smdebug.core.utils import setup_profiler_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.027639Z",
     "iopub.status.busy": "2022-01-20T11:12:57.027142Z",
     "iopub.status.idle": "2022-01-20T11:12:57.225130Z",
     "shell.execute_reply": "2022-01-20T11:12:57.225513Z"
    },
    "papermill": {
     "duration": 0.220512,
     "end_time": "2022-01-20T11:12:57.225655",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.005143",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models.widgets import DataTable, DateFormatter, TableColumn\n",
    "from bokeh.models import ColumnDataSource, PreText\n",
    "from math import pi\n",
    "from bokeh.transform import cumsum\n",
    "import warnings\n",
    "from bokeh.models.widgets import Paragraph\n",
    "from bokeh.models import Legend\n",
    "from bokeh.util.warnings import BokehDeprecationWarning, BokehUserWarning\n",
    "warnings.simplefilter('ignore', BokehDeprecationWarning)\n",
    "warnings.simplefilter('ignore', BokehUserWarning)\n",
    "\n",
    "output_notebook(hide_banner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.265089Z",
     "iopub.status.busy": "2022-01-20T11:12:57.264618Z",
     "iopub.status.idle": "2022-01-20T11:12:57.266778Z",
     "shell.execute_reply": "2022-01-20T11:12:57.266315Z"
    },
    "papermill": {
     "duration": 0.022936,
     "end_time": "2022-01-20T11:12:57.266875",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.243939",
     "status": "completed"
    },
    "tags": [
     "parameters",
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "processing_job_arn = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7da279b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.305674Z",
     "iopub.status.busy": "2022-01-20T11:12:57.305193Z",
     "iopub.status.idle": "2022-01-20T11:12:57.307285Z",
     "shell.execute_reply": "2022-01-20T11:12:57.306863Z"
    },
    "papermill": {
     "duration": 0.022623,
     "end_time": "2022-01-20T11:12:57.307382",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.284759",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "processing_job_arn = \"arn:aws:sagemaker:us-east-1:415073778672:processing-job/dogimageestimator-2022-01--profilerreport-39b1c02d\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.348929Z",
     "iopub.status.busy": "2022-01-20T11:12:57.348461Z",
     "iopub.status.idle": "2022-01-20T11:12:57.350146Z",
     "shell.execute_reply": "2022-01-20T11:12:57.350553Z"
    },
    "papermill": {
     "duration": 0.025459,
     "end_time": "2022-01-20T11:12:57.350665",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.325206",
     "status": "completed"
    },
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "setup_profiler_report(processing_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.393932Z",
     "iopub.status.busy": "2022-01-20T11:12:57.393454Z",
     "iopub.status.idle": "2022-01-20T11:12:57.395307Z",
     "shell.execute_reply": "2022-01-20T11:12:57.395692Z"
    },
    "papermill": {
     "duration": 0.027059,
     "end_time": "2022-01-20T11:12:57.395803",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.368744",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def create_piechart(data_dict, title=None, height=400, width=400, x1=0, x2=0.1, radius=0.4, toolbar_location='right'):\n",
    "   \n",
    "    plot = figure(plot_height=height, \n",
    "                  plot_width=width,\n",
    "                  toolbar_location=toolbar_location,\n",
    "                  tools=\"hover,wheel_zoom,reset,pan\", \n",
    "                  tooltips=\"@phase:@value\", \n",
    "                  title=title,\n",
    "                  x_range=(-radius-x1, radius+x2))\n",
    "\n",
    "    data = pd.Series(data_dict).reset_index(name='value').rename(columns={'index':'phase'})\n",
    "    data['angle'] = data['value']/data['value'].sum() * 2*pi\n",
    "    data['color'] = bokeh.palettes.viridis(len(data_dict))\n",
    "\n",
    "    plot.wedge(x=0, y=0., radius=radius,\n",
    "        start_angle=cumsum('angle', include_zero=True), \n",
    "        end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", \n",
    "        source=data, \n",
    "        fill_color='color', \n",
    "        legend='phase'\n",
    "              )\n",
    "    plot.legend.label_text_font_size = \"8pt\"\n",
    "    plot.legend.location = 'center_right'\n",
    "    plot.axis.axis_label=None\n",
    "    plot.axis.visible=False\n",
    "    plot.grid.grid_line_color = None\n",
    "    plot.outline_line_color = \"white\"\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.435548Z",
     "iopub.status.busy": "2022-01-20T11:12:57.435069Z",
     "iopub.status.idle": "2022-01-20T11:12:57.436747Z",
     "shell.execute_reply": "2022-01-20T11:12:57.437150Z"
    },
    "papermill": {
     "duration": 0.023495,
     "end_time": "2022-01-20T11:12:57.437262",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.413767",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown, Image\n",
    "def pretty_print(df):\n",
    "    raw_html = df.to_html().replace(\"\\\\n\",\"<br>\").replace('<tr>','<tr style=\"text-align: left;\">')\n",
    "    return display(HTML(raw_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017987,
     "end_time": "2022-01-20T11:12:57.473341",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.455354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training job summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.513396Z",
     "iopub.status.busy": "2022-01-20T11:12:57.512924Z",
     "iopub.status.idle": "2022-01-20T11:12:57.514650Z",
     "shell.execute_reply": "2022-01-20T11:12:57.515044Z"
    },
    "papermill": {
     "duration": 0.023677,
     "end_time": "2022-01-20T11:12:57.515157",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.491480",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def load_report(rule_name):\n",
    "    try:\n",
    "        report = json.load(open('/opt/ml/processing/output/rule/profiler-output/profiler-reports/'+rule_name+'.json'))\n",
    "        return report\n",
    "    except FileNotFoundError:\n",
    "        print (rule_name + ' not triggered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.562306Z",
     "iopub.status.busy": "2022-01-20T11:12:57.554022Z",
     "iopub.status.idle": "2022-01-20T11:12:57.565519Z",
     "shell.execute_reply": "2022-01-20T11:12:57.565914Z"
    },
    "papermill": {
     "duration": 0.032489,
     "end_time": "2022-01-20T11:12:57.566052",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.533563",
     "status": "completed"
    },
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "job_statistics = {}\n",
    "report = load_report('MaxInitializationTime')\n",
    "if report:\n",
    "    if \"first\" in report['Details'][\"step_num\"] and \"last\" in report['Details'][\"step_num\"]:\n",
    "        first_step = report['Details'][\"step_num\"][\"first\"]\n",
    "        last_step = report['Details'][\"step_num\"][\"last\"]\n",
    "    tmp = us_since_epoch_to_human_readable_time(report['Details']['job_start'] * 1000000)\n",
    "    date = datetime.datetime.strptime(tmp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "    day = date.date().strftime(\"%m/%d/%Y\")\n",
    "    hour = date.time().strftime(\"%H:%M:%S\")\n",
    "    job_statistics[\"Start time\"] = f\"{hour} {day}\"\n",
    "    tmp = us_since_epoch_to_human_readable_time(report['Details']['job_end'] * 1000000)\n",
    "    date = datetime.datetime.strptime(tmp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "    day = date.date().strftime(\"%m/%d/%Y\")\n",
    "    hour = date.time().strftime(\"%H:%M:%S\")\n",
    "    job_statistics[\"End time\"] = f\"{hour} {day}\"\n",
    "    job_duration_in_seconds = int(report['Details']['job_end'] - report['Details']['job_start']) \n",
    "    job_statistics[\"Job duration\"] = f\"{job_duration_in_seconds} seconds\"\n",
    "    if \"first\" in report['Details'][\"step_num\"] and \"last\" in report['Details'][\"step_num\"]:\n",
    "        tmp = us_since_epoch_to_human_readable_time(first_step)\n",
    "        date = datetime.datetime.strptime(tmp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "        day = date.date().strftime(\"%m/%d/%Y\")\n",
    "        hour = date.time().strftime(\"%H:%M:%S\")\n",
    "        job_statistics[\"Training loop start\"] = f\"{hour} {day}\"\n",
    "        tmp = us_since_epoch_to_human_readable_time(last_step)\n",
    "        date = datetime.datetime.strptime(tmp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "        day = date.date().strftime(\"%m/%d/%Y\")\n",
    "        hour = date.time().strftime(\"%H:%M:%S\")\n",
    "        job_statistics[\"Training loop end\"] = f\"{hour} {day}\"\n",
    "        training_loop_duration_in_seconds = int((last_step - first_step) / 1000000)\n",
    "        job_statistics[\"Training loop duration\"] = f\"{training_loop_duration_in_seconds} seconds\"\n",
    "        initialization_in_seconds = int(first_step/1000000 - report['Details']['job_start'])\n",
    "        job_statistics[\"Initialization time\"] = f\"{initialization_in_seconds} seconds\"\n",
    "        finalization_in_seconds = int(np.abs(report['Details']['job_end'] - last_step/1000000))\n",
    "        job_statistics[\"Finalization time\"] = f\"{finalization_in_seconds} seconds\"\n",
    "        initialization_perc = int(initialization_in_seconds / job_duration_in_seconds * 100)\n",
    "        job_statistics[\"Initialization\"] = f\"{initialization_perc} %\"\n",
    "        training_loop_perc = int(training_loop_duration_in_seconds / job_duration_in_seconds * 100)\n",
    "        job_statistics[\"Training loop\"] = f\"{training_loop_perc} %\"\n",
    "        finalization_perc = int(finalization_in_seconds / job_duration_in_seconds * 100)\n",
    "        job_statistics[\"Finalization\"] = f\"{finalization_perc} %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.632160Z",
     "iopub.status.busy": "2022-01-20T11:12:57.621446Z",
     "iopub.status.idle": "2022-01-20T11:12:57.651377Z",
     "shell.execute_reply": "2022-01-20T11:12:57.650918Z"
    },
    "papermill": {
     "duration": 0.066878,
     "end_time": "2022-01-20T11:12:57.651489",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.584611",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"b979b092-1791-4f68-b439-168f23e89c59\" data-root-id=\"1052\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"42a38f7a-75ca-45f6-b324-0846469617cd\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1050\"},{\"id\":\"1051\"}]},\"id\":\"1052\",\"type\":\"Column\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1035\"}},\"id\":\"1040\",\"type\":\"CDSView\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1034\"},\"units\":\"rad\"},\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.15},\"start_angle\":{\"expr\":{\"id\":\"1033\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1037\",\"type\":\"Wedge\"},{\"attributes\":{\"editor\":{\"id\":\"1057\"},\"field\":\"0\",\"formatter\":{\"id\":\"1056\"},\"title\":\"\"},\"id\":\"1002\",\"type\":\"TableColumn\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"BasicTicker\"},{\"attributes\":{\"field\":\"angle\",\"include_zero\":true},\"id\":\"1033\",\"type\":\"CumSum\"},{\"attributes\":{\"field\":\"angle\"},\"id\":\"1034\",\"type\":\"CumSum\"},{\"attributes\":{\"end\":0.3,\"start\":-0.3},\"id\":\"1008\",\"type\":\"Range1d\"},{\"attributes\":{\"axis\":{\"id\":\"1020\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1023\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1042\"},\"ticker\":{\"id\":\"1021\"},\"visible\":false},\"id\":\"1020\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"ResetTool\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1034\"},\"units\":\"rad\"},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.15},\"start_angle\":{\"expr\":{\"id\":\"1033\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1038\",\"type\":\"Wedge\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"Selection\"},{\"attributes\":{\"below\":[{\"id\":\"1016\"}],\"center\":[{\"id\":\"1019\"},{\"id\":\"1023\"},{\"id\":\"1048\"}],\"left\":[{\"id\":\"1020\"}],\"outline_line_color\":\"white\",\"plot_height\":350,\"plot_width\":500,\"renderers\":[{\"id\":\"1039\"}],\"title\":null,\"toolbar\":{\"id\":\"1028\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"1008\"},\"x_scale\":{\"id\":\"1012\"},\"y_range\":{\"id\":\"1010\"},\"y_scale\":{\"id\":\"1014\"}},\"id\":\"1006\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"editor\":{\"id\":\"1059\"},\"field\":\"1\",\"formatter\":{\"id\":\"1058\"},\"title\":\"Job Statistics\"},\"id\":\"1003\",\"type\":\"TableColumn\"},{\"attributes\":{\"items\":[{\"id\":\"1049\"}],\"label_text_font_size\":\"8pt\",\"location\":\"center_right\"},\"id\":\"1048\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1058\",\"type\":\"StringFormatter\"},{\"attributes\":{\"label\":{\"field\":\"phase\"},\"renderers\":[{\"id\":\"1039\"}]},\"id\":\"1049\",\"type\":\"LegendItem\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"},{\"id\":\"1027\"}]},\"id\":\"1028\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"tooltips\":\"@phase:@value\"},\"id\":\"1024\",\"type\":\"HoverTool\"},{\"attributes\":{\"columns\":[{\"id\":\"1002\"},{\"id\":\"1003\"}],\"height\":380,\"source\":{\"id\":\"1001\"},\"view\":{\"id\":\"1005\"},\"width\":450},\"id\":\"1004\",\"type\":\"DataTable\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"text\":\"The following table gives a summary about the training job. The table includes information about when the training job started and ended, how much time initialization, training loop and finalization took. \\n Your training job started on 01/20/2022 at 10:45:06 and ran for 1613 seconds.\",\"width\":800},\"id\":\"1050\",\"type\":\"Paragraph\"},{\"attributes\":{\"children\":[{\"id\":\"1004\"},{\"id\":\"1006\"}]},\"id\":\"1051\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"1056\",\"type\":\"StringFormatter\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1054\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1057\",\"type\":\"StringEditor\"},{\"attributes\":{},\"id\":\"1027\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1044\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data\":{\"0\":[\"Start time\",\"End time\",\"Job duration\",\"Training loop start\",\"Training loop end\",\"Training loop duration\",\"Initialization time\",\"Finalization time\",\"Initialization\",\"Training loop\",\"Finalization\"],\"1\":[\"10:45:06 01/20/2022\",\"11:11:59 01/20/2022\",\"1613 seconds\",\"10:47:31 01/20/2022\",\"11:11:49 01/20/2022\",\"1457 seconds\",\"145 seconds\",\"10 seconds\",\"8 %\",\"90 %\",\"0 %\"],\"index\":[0,1,2,3,4,5,6,7,8,9,10]},\"selected\":{\"id\":\"1054\"},\"selection_policy\":{\"id\":\"1055\"}},\"id\":\"1001\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1055\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1059\",\"type\":\"StringEditor\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"1035\"},\"glyph\":{\"id\":\"1037\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1038\"},\"selection_glyph\":null,\"view\":{\"id\":\"1040\"}},\"id\":\"1039\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data\":{\"angle\":{\"__ndarray__\":\"kjdrtMhp4D8mxrY9whQXQAAAAAAAAAAA\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[3]},\"color\":[\"#440154\",\"#208F8C\",\"#FDE724\"],\"index\":[0,1,2],\"phase\":[\"Initialization\",\"Training loop\",\"Finalization\"],\"value\":[8,90,0]},\"selected\":{\"id\":\"1046\"},\"selection_policy\":{\"id\":\"1047\"}},\"id\":\"1035\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1044\"},\"ticker\":{\"id\":\"1017\"},\"visible\":false},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"1001\"}},\"id\":\"1005\",\"type\":\"CDSView\"}],\"root_ids\":[\"1052\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"42a38f7a-75ca-45f6-b324-0846469617cd\",\"root_ids\":[\"1052\"],\"roots\":{\"1052\":\"b979b092-1791-4f68-b439-168f23e89c59\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1052"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if report:\n",
    "    text =  \"\"\"The following table gives a summary about the training job. The table includes information about when the training job started and ended, how much time initialization, training loop and finalization took.\"\"\"\n",
    "    if len(job_statistics) > 0:\n",
    "        df = pd.DataFrame.from_dict(job_statistics, orient='index')\n",
    "        start_time = us_since_epoch_to_human_readable_time(report['Details']['job_start'] * 1000000)\n",
    "        date = datetime.datetime.strptime(start_time, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "        day = date.date().strftime(\"%m/%d/%Y\")\n",
    "        hour = date.time().strftime(\"%H:%M:%S\")\n",
    "        duration = job_duration_in_seconds\n",
    "        text = f\"\"\"{text} \\n Your training job started on {day} at {hour} and ran for {duration} seconds.\"\"\"\n",
    "\n",
    "        #pretty_print(df)\n",
    "        if \"first\" in report['Details'][\"step_num\"] and \"last\" in report['Details'][\"step_num\"]:\n",
    "            if finalization_perc  < 0:\n",
    "                job_statistics[\"Finalization%\"]  = 0\n",
    "            if training_loop_perc < 0:\n",
    "                job_statistics[\"Training loop\"] = 0\n",
    "            if initialization_perc < 0:\n",
    "                job_statistics[\"Initialization\"] = 0\n",
    "        else:\n",
    "            text = f\"\"\"{text} \\n Your training job started on {day} at {hour} and ran for {duration} seconds.\"\"\"\n",
    "            \n",
    "    if len(job_statistics) > 0:\n",
    "        df2 = df.reset_index()\n",
    "        df2.columns = [\"0\", \"1\"]\n",
    "        source = ColumnDataSource(data=df2)\n",
    "        columns = [TableColumn(field='0', title=\"\"),\n",
    "                   TableColumn(field='1', title=\"Job Statistics\"),]\n",
    "        table = DataTable(source=source, columns=columns, width=450, height=380)\n",
    "\n",
    "    plot = None\n",
    "\n",
    "    if \"Initialization\" in job_statistics:\n",
    "        piechart_data = {}\n",
    "        piechart_data[\"Initialization\"] = initialization_perc  \n",
    "        piechart_data[\"Training loop\"]  = training_loop_perc\n",
    "        piechart_data[\"Finalization\"]  = finalization_perc \n",
    "\n",
    "        plot = create_piechart(piechart_data, \n",
    "                               height=350,\n",
    "                               width=500,\n",
    "                               x1=0.15,\n",
    "                               x2=0.15,\n",
    "                               radius=0.15, \n",
    "                               toolbar_location=None)\n",
    "\n",
    "    if plot != None:\n",
    "        paragraph = Paragraph(text=f\"\"\"{text}\"\"\", width = 800)\n",
    "        show(column(paragraph, row(table, plot)))\n",
    "    else:\n",
    "        paragraph = Paragraph(text=f\"\"\"{text}. No step information was profiled from your training job. The time spent on initialization and finalization cannot be computed.\"\"\" , width = 800)\n",
    "        show(column(paragraph, row(table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019322,
     "end_time": "2022-01-20T11:12:57.690450",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.671128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## System usage statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.732750Z",
     "iopub.status.busy": "2022-01-20T11:12:57.732275Z",
     "iopub.status.idle": "2022-01-20T11:12:57.734541Z",
     "shell.execute_reply": "2022-01-20T11:12:57.734129Z"
    },
    "papermill": {
     "duration": 0.02509,
     "end_time": "2022-01-20T11:12:57.734647",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.709557",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "report = load_report('OverallSystemUsage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.781412Z",
     "iopub.status.busy": "2022-01-20T11:12:57.780766Z",
     "iopub.status.idle": "2022-01-20T11:12:57.783223Z",
     "shell.execute_reply": "2022-01-20T11:12:57.782786Z"
    },
    "papermill": {
     "duration": 0.029472,
     "end_time": "2022-01-20T11:12:57.783329",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.753857",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "text1 = ''\n",
    "if report:\n",
    "    if \"GPU\" in report[\"Details\"]:\n",
    "        for node_id in report[\"Details\"][\"GPU\"]:\n",
    "            gpu_p95 = report[\"Details\"][\"GPU\"][node_id][\"p95\"]\n",
    "            gpu_p50 = report[\"Details\"][\"GPU\"][node_id][\"p50\"]\n",
    "            cpu_p95 = report[\"Details\"][\"CPU\"][node_id][\"p95\"]\n",
    "            cpu_p50 = report[\"Details\"][\"CPU\"][node_id][\"p50\"]\n",
    "            \n",
    "            if gpu_p95 < 70 and cpu_p95 < 70:\n",
    "                text1 = f\"\"\"{text1}The 95th percentile of the total GPU utilization on node {node_id} is only {int(gpu_p95)}%. \n",
    "                The 95th percentile of the total CPU utilization is only {int(cpu_p95)}%. Node {node_id} is underutilized. \n",
    "                You may want to consider switching to a smaller instance type.\"\"\"\n",
    "            elif gpu_p95 < 70 and cpu_p95 > 70:\n",
    "                text1 = f\"\"\"{text1}The 95th percentile of the total GPU utilization on node {node_id} is only {int(gpu_p95)}%. \n",
    "                However, the 95th percentile of the total CPU utilization is {int(cpu_p95)}%. GPUs on node {node_id} are underutilized, \n",
    "                likely because of CPU bottlenecks.\"\"\"\n",
    "            elif gpu_p50 > 70:\n",
    "                text1 = f\"\"\"{text1}The median total GPU utilization on node {node_id} is {int(gpu_p50)}%. \n",
    "                GPUs on node {node_id} are well utilized.\"\"\"\n",
    "            else:\n",
    "                text1 = f\"\"\"{text1}The median total GPU utilization on node {node_id} is {int(gpu_p50)}%. \n",
    "                The median total CPU utilization is {int(cpu_p50)}%.\"\"\"\n",
    "    else:\n",
    "        for node_id in report[\"Details\"][\"CPU\"]:\n",
    "            cpu_p95 = report[\"Details\"][\"CPU\"][node_id][\"p95\"]\n",
    "            if cpu_p95 > 70:\n",
    "                text1 = f\"\"\"{text1}The 95th percentile of the total CPU utilization on node {node_id} is {int**(cpu_p95)}%. CPUs on node {node_id} are well utilized.\"\"\"\n",
    "    text1 = Paragraph(text=f\"\"\"{text1}\"\"\", width=1100)\n",
    "    text2 = Paragraph(text=f\"\"\"The following table shows statistics of resource utilization per worker (node), \n",
    "    such as the total CPU and GPU utilization, and the memory utilization on CPU and GPU. \n",
    "    The table also includes the total I/O wait time and the total amount of data sent or received in bytes.\n",
    "    The table shows min and max values as well as p99, p90 and p50 percentiles.\"\"\", width=900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.831893Z",
     "iopub.status.busy": "2022-01-20T11:12:57.830873Z",
     "iopub.status.idle": "2022-01-20T11:12:57.852021Z",
     "shell.execute_reply": "2022-01-20T11:12:57.852379Z"
    },
    "papermill": {
     "duration": 0.049803,
     "end_time": "2022-01-20T11:12:57.852508",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.802705",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"793bccf6-49ac-4416-bfd9-e118a9764f64\" data-root-id=\"1145\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"3f537fd2-5ebf-4420-a8f2-b3ae4b3e5faa\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1131\"},{\"id\":\"1132\"},{\"id\":\"1144\"}]},\"id\":\"1145\",\"type\":\"Column\"},{\"attributes\":{},\"id\":\"1161\",\"type\":\"StringFormatter\"},{\"attributes\":{\"data\":{\"Node\":[\"algo-1\",\"algo-1\",\"algo-1\",\"algo-1\"],\"index\":[0,1,2,3],\"level_0\":[0,1,2,3],\"max\":{\"__ndarray__\":\"9ihcj0J4rkAAAAAAAABZQM3MzMzMTEFAcT0K16PAWEA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[4]},\"metric\":[\"Network\",\"CPU\",\"CPU memory\",\"I/O\"],\"min\":{\"__ndarray__\":\"AAAAAAAAAAAAAAAAAAAAAOF6FK5H4R5AAAAAAAAAAAA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[4]},\"p50\":{\"__ndarray__\":\"AAAAAAAAAADD9Shcj4JJQOxRuB6FKzFAAAAAAAAAAAA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[4]},\"p95\":{\"__ndarray__\":\"AAAAAAAAAAAAAAAAAPBRQFyPwvUoHD1AAAAAAAAAAEA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[4]},\"p99\":{\"__ndarray__\":\"AAAAAAAAAAAK16NwPSpVQDMzMzMzM0BACtejcD1qQUA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[4]},\"unit\":[\"bytes\",\"percentage\",\"percentage\",\"percentage\"]},\"selected\":{\"id\":\"1159\"},\"selection_policy\":{\"id\":\"1160\"}},\"id\":\"1133\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"editor\":{\"id\":\"1164\"},\"field\":\"metric\",\"formatter\":{\"id\":\"1163\"},\"title\":\"metric\"},\"id\":\"1135\",\"type\":\"TableColumn\"},{\"attributes\":{},\"id\":\"1167\",\"type\":\"StringFormatter\"},{\"attributes\":{\"text\":\"The following table shows statistics of resource utilization per worker (node), \\n    such as the total CPU and GPU utilization, and the memory utilization on CPU and GPU. \\n    The table also includes the total I/O wait time and the total amount of data sent or received in bytes.\\n    The table shows min and max values as well as p99, p90 and p50 percentiles.\",\"width\":900},\"id\":\"1132\",\"type\":\"Paragraph\"},{\"attributes\":{\"source\":{\"id\":\"1133\"}},\"id\":\"1143\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1160\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"width\":1100},\"id\":\"1131\",\"type\":\"Paragraph\"},{\"attributes\":{},\"id\":\"1164\",\"type\":\"StringEditor\"},{\"attributes\":{\"columns\":[{\"id\":\"1134\"},{\"id\":\"1135\"},{\"id\":\"1136\"},{\"id\":\"1137\"},{\"id\":\"1138\"},{\"id\":\"1139\"},{\"id\":\"1140\"},{\"id\":\"1141\"}],\"height\":120,\"source\":{\"id\":\"1133\"},\"view\":{\"id\":\"1143\"},\"width\":800},\"id\":\"1142\",\"type\":\"DataTable\"},{\"attributes\":{},\"id\":\"1165\",\"type\":\"StringFormatter\"},{\"attributes\":{\"children\":[{\"id\":\"1142\"}]},\"id\":\"1144\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"1171\",\"type\":\"StringFormatter\"},{\"attributes\":{},\"id\":\"1175\",\"type\":\"StringFormatter\"},{\"attributes\":{\"editor\":{\"id\":\"1168\"},\"field\":\"max\",\"formatter\":{\"id\":\"1167\"},\"title\":\"max\"},\"id\":\"1137\",\"type\":\"TableColumn\"},{\"attributes\":{\"editor\":{\"id\":\"1166\"},\"field\":\"unit\",\"formatter\":{\"id\":\"1165\"},\"title\":\"unit\"},\"id\":\"1136\",\"type\":\"TableColumn\"},{\"attributes\":{},\"id\":\"1163\",\"type\":\"StringFormatter\"},{\"attributes\":{},\"id\":\"1169\",\"type\":\"StringFormatter\"},{\"attributes\":{},\"id\":\"1159\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1174\",\"type\":\"StringEditor\"},{\"attributes\":{},\"id\":\"1172\",\"type\":\"StringEditor\"},{\"attributes\":{},\"id\":\"1166\",\"type\":\"StringEditor\"},{\"attributes\":{\"editor\":{\"id\":\"1176\"},\"field\":\"min\",\"formatter\":{\"id\":\"1175\"},\"title\":\"min\"},\"id\":\"1141\",\"type\":\"TableColumn\"},{\"attributes\":{\"editor\":{\"id\":\"1170\"},\"field\":\"p99\",\"formatter\":{\"id\":\"1169\"},\"title\":\"p99\"},\"id\":\"1138\",\"type\":\"TableColumn\"},{\"attributes\":{},\"id\":\"1173\",\"type\":\"StringFormatter\"},{\"attributes\":{},\"id\":\"1176\",\"type\":\"StringEditor\"},{\"attributes\":{\"editor\":{\"id\":\"1162\"},\"field\":\"Node\",\"formatter\":{\"id\":\"1161\"},\"title\":\"node\"},\"id\":\"1134\",\"type\":\"TableColumn\"},{\"attributes\":{},\"id\":\"1168\",\"type\":\"StringEditor\"},{\"attributes\":{},\"id\":\"1162\",\"type\":\"StringEditor\"},{\"attributes\":{\"editor\":{\"id\":\"1172\"},\"field\":\"p95\",\"formatter\":{\"id\":\"1171\"},\"title\":\"p95\"},\"id\":\"1139\",\"type\":\"TableColumn\"},{\"attributes\":{\"editor\":{\"id\":\"1174\"},\"field\":\"p50\",\"formatter\":{\"id\":\"1173\"},\"title\":\"p50\"},\"id\":\"1140\",\"type\":\"TableColumn\"},{\"attributes\":{},\"id\":\"1170\",\"type\":\"StringEditor\"}],\"root_ids\":[\"1145\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"3f537fd2-5ebf-4420-a8f2-b3ae4b3e5faa\",\"root_ids\":[\"1145\"],\"roots\":{\"1145\":\"793bccf6-49ac-4416-bfd9-e118a9764f64\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1145"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "rows = [] \n",
    "units = {\"CPU\": \"percentage\", \"CPU memory\": \"percentage\", \"GPU\": \"percentage\", \"Network\": \"bytes\", \"GPU memory\": \"percentage\", \"I/O\": \"percentage\"}\n",
    "if report:\n",
    "    for metric in report['Details']:\n",
    "        for node_id in report['Details'][metric]:\n",
    "            values = report['Details'][metric][node_id]\n",
    "            rows.append([node_id, metric, units[metric], values['max'], values['p99'], values['p95'], values['p50'], values['min']])\n",
    "\n",
    "    df = pd.DataFrame(rows) \n",
    "    df.columns = ['Node', 'metric', 'unit', 'max', 'p99', 'p95', 'p50', 'min']\n",
    "    df2 = df.reset_index()\n",
    "    source = ColumnDataSource(data=df2)\n",
    "    columns = [TableColumn(field='Node', title=\"node\"),\n",
    "               TableColumn(field='metric', title=\"metric\"),\n",
    "               TableColumn(field='unit', title=\"unit\"),\n",
    "               TableColumn(field='max', title=\"max\"),\n",
    "               TableColumn(field='p99', title=\"p99\"),\n",
    "               TableColumn(field='p95', title=\"p95\"),\n",
    "               TableColumn(field='p50', title=\"p50\"),\n",
    "               TableColumn(field='min', title=\"min\"),]\n",
    "    table = DataTable(source=source, columns=columns, width=800, height=df2.shape[0]*30)\n",
    "\n",
    "    show(column( text1, text2, row(table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:57.909068Z",
     "iopub.status.busy": "2022-01-20T11:12:57.900755Z",
     "iopub.status.idle": "2022-01-20T11:12:57.997215Z",
     "shell.execute_reply": "2022-01-20T11:12:57.996724Z"
    },
    "papermill": {
     "duration": 0.124673,
     "end_time": "2022-01-20T11:12:57.997322",
     "exception": false,
     "start_time": "2022-01-20T11:12:57.872649",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Framework metrics summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"ecc54e8d-faef-42b0-bc15-f97178cd910d\" data-root-id=\"1314\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"df35fa24-c42d-4d06-ad2e-16c40e027c7e\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1312\"},{\"id\":\"1313\"}]},\"id\":\"1314\",\"type\":\"Column\"},{\"attributes\":{\"items\":[{\"id\":\"1311\"}],\"label_text_font_size\":\"8pt\",\"location\":\"center_right\"},\"id\":\"1310\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1283\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1279\",\"type\":\"BasicTicker\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1296\"},\"units\":\"rad\"},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.3},\"start_angle\":{\"expr\":{\"id\":\"1295\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1300\",\"type\":\"Wedge\"},{\"attributes\":{\"source\":{\"id\":\"1297\"}},\"id\":\"1302\",\"type\":\"CDSView\"},{\"attributes\":{\"axis\":{\"id\":\"1278\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1281\",\"type\":\"Grid\"},{\"attributes\":{\"label\":{\"field\":\"phase\"},\"renderers\":[{\"id\":\"1301\"}]},\"id\":\"1311\",\"type\":\"LegendItem\"},{\"attributes\":{\"axis\":{\"id\":\"1282\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1285\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1304\"},\"ticker\":{\"id\":\"1283\"},\"visible\":false},\"id\":\"1282\",\"type\":\"LinearAxis\"},{\"attributes\":{\"children\":[{\"id\":\"1267\"}]},\"id\":\"1313\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"1274\",\"type\":\"LinearScale\"},{\"attributes\":{\"below\":[{\"id\":\"1278\"}],\"center\":[{\"id\":\"1281\"},{\"id\":\"1285\"},{\"id\":\"1310\"}],\"left\":[{\"id\":\"1282\"}],\"outline_line_color\":\"white\",\"plot_height\":350,\"renderers\":[{\"id\":\"1301\"}],\"title\":{\"id\":\"1268\"},\"toolbar\":{\"id\":\"1290\"},\"x_range\":{\"id\":\"1270\"},\"x_scale\":{\"id\":\"1274\"},\"y_range\":{\"id\":\"1272\"},\"y_scale\":{\"id\":\"1276\"}},\"id\":\"1267\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1306\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"field\":\"angle\"},\"id\":\"1296\",\"type\":\"CumSum\"},{\"attributes\":{\"callback\":null,\"tooltips\":\"@phase:@value\"},\"id\":\"1286\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1287\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1286\"},{\"id\":\"1287\"},{\"id\":\"1288\"},{\"id\":\"1289\"}]},\"id\":\"1290\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1288\",\"type\":\"ResetTool\"},{\"attributes\":{\"field\":\"angle\",\"include_zero\":true},\"id\":\"1295\",\"type\":\"CumSum\"},{\"attributes\":{},\"id\":\"1289\",\"type\":\"PanTool\"},{\"attributes\":{\"data\":{\"angle\":{\"__ndarray__\":\"jyQYwQMCGUCCQ4rbti3Vvx7MSg4wLdc/\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[3]},\"color\":[\"#440154\",\"#208F8C\",\"#FDE724\"],\"index\":[0,1,2],\"phase\":[\"Step:ModeKeys.TRAIN\",\"others\",\"Step:ModeKeys.EVAL\"],\"value\":{\"__ndarray__\":\"2jHEpTPgWECQcMk0FBEVwPZShtjZDRdA\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[3]}},\"selected\":{\"id\":\"1308\"},\"selection_policy\":{\"id\":\"1309\"}},\"id\":\"1297\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"data_source\":{\"id\":\"1297\"},\"glyph\":{\"id\":\"1299\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1300\"},\"selection_glyph\":null,\"view\":{\"id\":\"1302\"}},\"id\":\"1301\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"text\":\"The ratio between the time spent on the TRAIN/EVAL phase and others\"},\"id\":\"1268\",\"type\":\"Title\"},{\"attributes\":{\"text\":\"The following two pie charts show the time spent on the TRAIN phase, the EVAL phase, \\n            and others. The 'others' includes the time spent between steps (after one step has finished and before\\n            the next step has started). Ideally, most of the training time should be spent on the \\n            TRAIN and EVAL phases. If TRAIN/EVAL were not specified in the training script, steps will be recorded as \\n            GLOBAL.\",\"width\":1100},\"id\":\"1312\",\"type\":\"Paragraph\"},{\"attributes\":{},\"id\":\"1304\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1296\"},\"units\":\"rad\"},\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.3},\"start_angle\":{\"expr\":{\"id\":\"1295\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1299\",\"type\":\"Wedge\"},{\"attributes\":{\"end\":0.8999999999999999,\"start\":-0.5},\"id\":\"1270\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"1308\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1276\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1272\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1309\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1306\"},\"ticker\":{\"id\":\"1279\"},\"visible\":false},\"id\":\"1278\",\"type\":\"LinearAxis\"}],\"root_ids\":[\"1314\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"df35fa24-c42d-4d06-ad2e-16c40e027c7e\",\"root_ids\":[\"1314\"],\"roots\":{\"1314\":\"ecc54e8d-faef-42b0-bc15-f97178cd910d\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1314"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"073b14db-f42c-4bf7-9d22-08138cb7ed04\" data-root-id=\"1480\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"1cfffbe0-5ae2-443d-b168-b3851acc1224\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1478\"},{\"id\":\"1479\"}]},\"id\":\"1480\",\"type\":\"Column\"},{\"attributes\":{},\"id\":\"1438\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1408\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null,\"tooltips\":\"@phase:@value\"},\"id\":\"1452\",\"type\":\"HoverTool\"},{\"attributes\":{\"below\":[{\"id\":\"1399\"}],\"center\":[{\"id\":\"1402\"},{\"id\":\"1406\"},{\"id\":\"1431\"}],\"left\":[{\"id\":\"1403\"}],\"outline_line_color\":\"white\",\"plot_height\":350,\"renderers\":[{\"id\":\"1422\"}],\"title\":{\"id\":\"1389\"},\"toolbar\":{\"id\":\"1411\"},\"x_range\":{\"id\":\"1391\"},\"x_scale\":{\"id\":\"1395\"},\"y_range\":{\"id\":\"1393\"},\"y_scale\":{\"id\":\"1397\"}},\"id\":\"1388\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"source\":{\"id\":\"1418\"}},\"id\":\"1423\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1475\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"callback\":null,\"tooltips\":\"@phase:@value\"},\"id\":\"1407\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1453\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1440\",\"type\":\"LinearScale\"},{\"attributes\":{\"data\":{\"angle\":{\"__ndarray__\":\"GC1EVPshGUA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[1]},\"color\":[\"#440154\"],\"index\":[0],\"phase\":[\"cpu_functions\"],\"value\":{\"__ndarray__\":\"AAAAAAAAWUA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[1]}},\"selected\":{\"id\":\"1429\"},\"selection_policy\":{\"id\":\"1430\"}},\"id\":\"1418\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"end\":0.8999999999999999,\"start\":-0.5},\"id\":\"1391\",\"type\":\"Range1d\"},{\"attributes\":{\"label\":{\"field\":\"phase\"},\"renderers\":[{\"id\":\"1422\"}]},\"id\":\"1432\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1454\",\"type\":\"ResetTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1452\"},{\"id\":\"1453\"},{\"id\":\"1454\"},{\"id\":\"1455\"}]},\"id\":\"1456\",\"type\":\"Toolbar\"},{\"attributes\":{\"end\":0.8999999999999999,\"start\":-0.5},\"id\":\"1436\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"1455\",\"type\":\"PanTool\"},{\"attributes\":{\"data\":{\"angle\":{\"__ndarray__\":\"ClQEA0Sc8T4C9kwWB53RP/dcznsmCBhA\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[3]},\"color\":[\"#440154\",\"#208F8C\",\"#FDE724\"],\"index\":[0,1,2],\"phase\":[\"DataLoaderIterInitialize\",\"DataLoaderIter\",\"Forward\"],\"value\":{\"__ndarray__\":\"RlIVbXSEMT/Qfpt4NoURQM4sWTeo51dA\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[3]}},\"selected\":{\"id\":\"1474\"},\"selection_policy\":{\"id\":\"1475\"}},\"id\":\"1463\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"field\":\"angle\"},\"id\":\"1417\",\"type\":\"CumSum\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1407\"},{\"id\":\"1408\"},{\"id\":\"1409\"},{\"id\":\"1410\"}]},\"id\":\"1411\",\"type\":\"Toolbar\"},{\"attributes\":{\"data_source\":{\"id\":\"1463\"},\"glyph\":{\"id\":\"1465\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1466\"},\"selection_glyph\":null,\"view\":{\"id\":\"1468\"}},\"id\":\"1467\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1472\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1429\",\"type\":\"Selection\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1417\"},\"units\":\"rad\"},\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.3},\"start_angle\":{\"expr\":{\"id\":\"1416\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1420\",\"type\":\"Wedge\"},{\"attributes\":{},\"id\":\"1474\",\"type\":\"Selection\"},{\"attributes\":{\"below\":[{\"id\":\"1444\"}],\"center\":[{\"id\":\"1447\"},{\"id\":\"1451\"},{\"id\":\"1476\"}],\"left\":[{\"id\":\"1448\"}],\"outline_line_color\":\"white\",\"plot_height\":350,\"renderers\":[{\"id\":\"1467\"}],\"title\":{\"id\":\"1434\"},\"toolbar\":{\"id\":\"1456\"},\"x_range\":{\"id\":\"1436\"},\"x_scale\":{\"id\":\"1440\"},\"y_range\":{\"id\":\"1438\"},\"y_scale\":{\"id\":\"1442\"}},\"id\":\"1433\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1445\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1442\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1409\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1410\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1449\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1472\"},\"ticker\":{\"id\":\"1445\"},\"visible\":false},\"id\":\"1444\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1400\",\"type\":\"BasicTicker\"},{\"attributes\":{\"field\":\"angle\"},\"id\":\"1462\",\"type\":\"CumSum\"},{\"attributes\":{\"text\":\"The ratio between the time spent on CPU/GPU operators\"},\"id\":\"1389\",\"type\":\"Title\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1417\"},\"units\":\"rad\"},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.3},\"start_angle\":{\"expr\":{\"id\":\"1416\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1421\",\"type\":\"Wedge\"},{\"attributes\":{},\"id\":\"1470\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1399\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1402\",\"type\":\"Grid\"},{\"attributes\":{\"data_source\":{\"id\":\"1418\"},\"glyph\":{\"id\":\"1420\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1421\"},\"selection_glyph\":null,\"view\":{\"id\":\"1423\"}},\"id\":\"1422\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1425\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1462\"},\"units\":\"rad\"},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.3},\"start_angle\":{\"expr\":{\"id\":\"1461\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1466\",\"type\":\"Wedge\"},{\"attributes\":{\"items\":[{\"id\":\"1477\"}],\"label_text_font_size\":\"8pt\",\"location\":\"center_right\"},\"id\":\"1476\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1430\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"items\":[{\"id\":\"1432\"}],\"label_text_font_size\":\"8pt\",\"location\":\"center_right\"},\"id\":\"1431\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1427\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"source\":{\"id\":\"1463\"}},\"id\":\"1468\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1395\",\"type\":\"LinearScale\"},{\"attributes\":{\"text\":\"The following piechart shows a breakdown of the CPU/GPU operators. \\n                It shows that 100% of training time was spent on executing the \\\"cpu_functions\\\" operator.\",\"width\":1100},\"id\":\"1478\",\"type\":\"Paragraph\"},{\"attributes\":{\"label\":{\"field\":\"phase\"},\"renderers\":[{\"id\":\"1467\"}]},\"id\":\"1477\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1393\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis\":{\"id\":\"1403\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1406\",\"type\":\"Grid\"},{\"attributes\":{\"text\":\"General framework operations\"},\"id\":\"1434\",\"type\":\"Title\"},{\"attributes\":{\"children\":[{\"id\":\"1388\"},{\"id\":\"1433\"}]},\"id\":\"1479\",\"type\":\"Row\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1427\"},\"ticker\":{\"id\":\"1400\"},\"visible\":false},\"id\":\"1399\",\"type\":\"LinearAxis\"},{\"attributes\":{\"axis\":{\"id\":\"1444\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1447\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1470\"},\"ticker\":{\"id\":\"1449\"},\"visible\":false},\"id\":\"1448\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1397\",\"type\":\"LinearScale\"},{\"attributes\":{\"field\":\"angle\",\"include_zero\":true},\"id\":\"1416\",\"type\":\"CumSum\"},{\"attributes\":{\"field\":\"angle\",\"include_zero\":true},\"id\":\"1461\",\"type\":\"CumSum\"},{\"attributes\":{\"axis\":{\"id\":\"1448\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1451\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1404\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1425\"},\"ticker\":{\"id\":\"1404\"},\"visible\":false},\"id\":\"1403\",\"type\":\"LinearAxis\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1462\"},\"units\":\"rad\"},\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.3},\"start_angle\":{\"expr\":{\"id\":\"1461\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1465\",\"type\":\"Wedge\"}],\"root_ids\":[\"1480\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"1cfffbe0-5ae2-443d-b168-b3851acc1224\",\"root_ids\":[\"1480\"],\"roots\":{\"1480\":\"073b14db-f42c-4bf7-9d22-08138cb7ed04\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1480"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = load_report('OverallFrameworkMetrics')\n",
    "if report:\n",
    "    if 'Details' in report:\n",
    "\n",
    "        display(Markdown(f\"\"\"## Framework metrics summary\"\"\"))\n",
    "        plots = []\n",
    "        text = ''\n",
    "        if 'phase' in report['Details']:\n",
    "            text = f\"\"\"The following two pie charts show the time spent on the TRAIN phase, the EVAL phase, \n",
    "            and others. The 'others' includes the time spent between steps (after one step has finished and before\n",
    "            the next step has started). Ideally, most of the training time should be spent on the \n",
    "            TRAIN and EVAL phases. If TRAIN/EVAL were not specified in the training script, steps will be recorded as \n",
    "            GLOBAL.\"\"\"\n",
    "\n",
    "            if 'others' in report['Details']['phase']:\n",
    "                others = float(report['Details']['phase']['others'])\n",
    "\n",
    "                if others > 25:\n",
    "                    text = f\"\"\"{text} Your training job spent quite a significant amount of time ({round(others,2)}%) in phase \"others\".\n",
    "                    You should check what is happening in between the steps.\"\"\"\n",
    "\n",
    "                plot = create_piechart(report['Details']['phase'], \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"The ratio between the time spent on the TRAIN/EVAL phase and others\")\n",
    "                plots.append(plot)\n",
    "\n",
    "        if 'forward_backward' in report['Details']:\n",
    "\n",
    "            event = max(report['Details']['forward_backward'], key=report['Details']['forward_backward'].get)\n",
    "            perc = report['Details']['forward_backward'][event]\n",
    "\n",
    "            text = f\"\"\"{text} The pie chart on the right shows a more detailed breakdown. \n",
    "            It shows that {int(perc)}% of the time was spent in event \"{event}\".\"\"\"\n",
    "\n",
    "            if perc > 70:\n",
    "                text = f\"\"\"There is quite a significant difference between the time spent on forward and backward\n",
    "                pass.\"\"\"\n",
    "            else:\n",
    "                text = f\"\"\"{text} It shows that {int(perc)}% of the training time\n",
    "                was spent on \"{event}\".\"\"\"\n",
    "\n",
    "            plot = create_piechart(report['Details']['forward_backward'], \n",
    "                                height=350,\n",
    "                                width=600,\n",
    "                                x1=0.2,\n",
    "                                x2=0.6,\n",
    "                                radius=0.3, \n",
    "                                title=\"The ratio between forward and backward pass\") \n",
    "            plots.append(plot)\n",
    "\n",
    "        if len(plots) > 0:\n",
    "            paragraph = Paragraph(text=text, width=1100)\n",
    "            show(column(paragraph, row(plots)))\n",
    "\n",
    "        plots = []\n",
    "        text=''\n",
    "        if 'ratio' in report['Details'] and len(report['Details']['ratio']) > 0:\n",
    "\n",
    "            key = list(report['Details']['ratio'].keys())[0]\n",
    "            ratio = report['Details']['ratio'][key]\n",
    "\n",
    "            text = f\"\"\"The following piechart shows a breakdown of the CPU/GPU operators. \n",
    "                It shows that {int(ratio)}% of training time was spent on executing the \"{key}\" operator.\"\"\"\n",
    "\n",
    "            plot = create_piechart(report['Details']['ratio'], \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"The ratio between the time spent on CPU/GPU operators\")\n",
    "            plots.append(plot)\n",
    "\n",
    "\n",
    "        if 'general' in report['Details']:\n",
    "            event = max(report['Details']['general'], key=report['Details']['general'].get)\n",
    "            perc = report['Details']['general'][event]\n",
    "\n",
    "            plot = create_piechart(report['Details']['general'], \n",
    "                                height=350,\n",
    "                                width=600,\n",
    "                                x1=0.2,\n",
    "                                x2=0.6,\n",
    "                                radius=0.3, \n",
    "                                title=\"General framework operations\")\n",
    "            plots.append(plot)\n",
    "\n",
    "        if len(plots) > 0:\n",
    "            paragraph = Paragraph(text=text, width=1100)\n",
    "            show(column(paragraph, row(plots)))\n",
    "\n",
    "        plots = []\n",
    "        text = ''\n",
    "        if 'horovod' in report['Details']:\n",
    "            display(Markdown(f\"\"\"#### Overview: Horovod metrics\"\"\"))\n",
    "            event = max(report['Details']['horovod'], key=report['Details']['horovod'].get)\n",
    "            perc = report['Details']['horovod'][event]\n",
    "            text = f\"\"\"{text} The following pie chart shows a detailed breakdown of the Horovod metrics profiled\n",
    "            from your training job. The most expensive function was \"{event}\" with {int(perc)}%.\"\"\"\n",
    "\n",
    "            plot = create_piechart(report['Details']['horovod'], \n",
    "                                height=350,\n",
    "                                width=600,\n",
    "                                x1=0.2,\n",
    "                                x2=0.6,\n",
    "                                radius=0.3, \n",
    "                                title=\"Horovod metrics \")\n",
    "\n",
    "            paragraph = Paragraph(text=text, width=1100)\n",
    "            show(column(paragraph, row(plot)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.049372Z",
     "iopub.status.busy": "2022-01-20T11:12:58.048097Z",
     "iopub.status.idle": "2022-01-20T11:12:58.092547Z",
     "shell.execute_reply": "2022-01-20T11:12:58.092064Z"
    },
    "papermill": {
     "duration": 0.073448,
     "end_time": "2022-01-20T11:12:58.092650",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.019202",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Overview: CPU operators"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"bdc39357-cd88-4d97-a252-4a1dc1460f96\" data-root-id=\"1655\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"29092e4f-4c6c-49cf-b6c2-2f3f3e504800\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1609\"},{\"id\":\"1654\"}]},\"id\":\"1655\",\"type\":\"Column\"},{\"attributes\":{},\"id\":\"1711\",\"type\":\"StringFormatter\"},{\"attributes\":{\"end\":0.8999999999999999,\"start\":-0.5},\"id\":\"1612\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"1712\",\"type\":\"StringEditor\"},{\"attributes\":{},\"id\":\"1618\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"tooltips\":\"@phase:@value\"},\"id\":\"1628\",\"type\":\"HoverTool\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1648\"},\"ticker\":{\"id\":\"1621\"},\"visible\":false},\"id\":\"1620\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1714\",\"type\":\"StringEditor\"},{\"attributes\":{\"below\":[{\"id\":\"1620\"}],\"center\":[{\"id\":\"1623\"},{\"id\":\"1627\"},{\"id\":\"1652\"}],\"left\":[{\"id\":\"1624\"}],\"outline_line_color\":\"white\",\"plot_height\":350,\"renderers\":[{\"id\":\"1643\"}],\"title\":null,\"toolbar\":{\"id\":\"1632\"},\"x_range\":{\"id\":\"1612\"},\"x_scale\":{\"id\":\"1616\"},\"y_range\":{\"id\":\"1614\"},\"y_scale\":{\"id\":\"1618\"}},\"id\":\"1610\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1715\",\"type\":\"StringFormatter\"},{\"attributes\":{},\"id\":\"1621\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data\":{\"angle\":{\"__ndarray__\":\"1GEdP7co8T9/SFx1qSjxPxohsROeKPE/lu+6x3Uo8T9trnDNrvPVP3tO6SpQ89U/V4EfBvny1T8ut3cyY1vGP/EfqExwDMY/zT1RowDE4z8=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[10]},\"color\":[\"#440154\",\"#472777\",\"#3E4989\",\"#30678D\",\"#25828E\",\"#1E9C89\",\"#35B778\",\"#6BCD59\",\"#B2DD2C\",\"#FDE724\"],\"index\":[0,1,2,3,4,5,6,7,8,9],\"phase\":[\"aten::conv2d\",\"aten::convolution\",\"aten::_convolution\",\"aten::mkldnn_convolution\",\"aten::batch_norm\",\"aten::_batch_norm_impl_index\",\"aten::native_batch_norm\",\"aten::max_pool2d\",\"aten::max_pool2d_with_indices\",\"enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__\"],\"value\":{\"__ndarray__\":\"pbUR5YMRMUDoKPUtdhExQBaNrdtqETFAKnozxkIRMUDqbsl6ANYVQASINlii1RVANz5AqUvVFUDBq/enKD0GQF9pIYGg7gVAjdTJDUepI0A=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[10]}},\"selected\":{\"id\":\"1650\"},\"selection_policy\":{\"id\":\"1651\"}},\"id\":\"1639\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"data_source\":{\"id\":\"1639\"},\"glyph\":{\"id\":\"1641\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1642\"},\"selection_glyph\":null,\"view\":{\"id\":\"1644\"}},\"id\":\"1643\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1630\",\"type\":\"ResetTool\"},{\"attributes\":{\"text\":\"The following table shows a list of operators that ran on the CPUs.\\n        The most expensive operator on the CPUs was \\\"aten::conv2d\\\" with 17 %.\"},\"id\":\"1609\",\"type\":\"Paragraph\"},{\"attributes\":{\"axis\":{\"id\":\"1620\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1623\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1716\",\"type\":\"StringEditor\"},{\"attributes\":{\"editor\":{\"id\":\"1712\"},\"field\":\"percentage\",\"formatter\":{\"id\":\"1711\"},\"title\":\"Percentage\"},\"id\":\"1604\",\"type\":\"TableColumn\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1628\"},{\"id\":\"1629\"},{\"id\":\"1630\"},{\"id\":\"1631\"}]},\"id\":\"1632\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"1624\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1627\",\"type\":\"Grid\"},{\"attributes\":{\"editor\":{\"id\":\"1716\"},\"field\":\"operator\",\"formatter\":{\"id\":\"1715\"},\"title\":\"CPU operator\"},\"id\":\"1606\",\"type\":\"TableColumn\"},{\"attributes\":{},\"id\":\"1631\",\"type\":\"PanTool\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1638\"},\"units\":\"rad\"},\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.3},\"start_angle\":{\"expr\":{\"id\":\"1637\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1641\",\"type\":\"Wedge\"},{\"attributes\":{\"field\":\"angle\"},\"id\":\"1638\",\"type\":\"CumSum\"},{\"attributes\":{\"editor\":{\"id\":\"1714\"},\"field\":\"time\",\"formatter\":{\"id\":\"1713\"},\"title\":\"Cumulative time in microseconds\"},\"id\":\"1605\",\"type\":\"TableColumn\"},{\"attributes\":{\"axis_label\":null,\"formatter\":{\"id\":\"1646\"},\"ticker\":{\"id\":\"1625\"},\"visible\":false},\"id\":\"1624\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1646\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1625\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1651\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1713\",\"type\":\"StringFormatter\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1638\"},\"units\":\"rad\"},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.3},\"start_angle\":{\"expr\":{\"id\":\"1637\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":0.0}},\"id\":\"1642\",\"type\":\"Wedge\"},{\"attributes\":{\"items\":[{\"id\":\"1653\"}],\"label_text_font_size\":\"8pt\",\"location\":\"center_right\"},\"id\":\"1652\",\"type\":\"Legend\"},{\"attributes\":{\"children\":[{\"id\":\"1607\"},{\"id\":\"1610\"}]},\"id\":\"1654\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"1629\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1616\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1614\",\"type\":\"DataRange1d\"},{\"attributes\":{\"source\":{\"id\":\"1639\"}},\"id\":\"1644\",\"type\":\"CDSView\"},{\"attributes\":{\"label\":{\"field\":\"phase\"},\"renderers\":[{\"id\":\"1643\"}]},\"id\":\"1653\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"1603\"}},\"id\":\"1608\",\"type\":\"CDSView\"},{\"attributes\":{\"field\":\"angle\",\"include_zero\":true},\"id\":\"1637\",\"type\":\"CumSum\"},{\"attributes\":{},\"id\":\"1709\",\"type\":\"Selection\"},{\"attributes\":{\"data\":{\"index\":[0,1,2,3,9,4,5,6,7,8],\"operator\":[\"aten::conv2d\",\"aten::convolution\",\"aten::_convolution\",\"aten::mkldnn_convolution\",\"enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__\",\"aten::batch_norm\",\"aten::_batch_norm_impl_index\",\"aten::native_batch_norm\",\"aten::max_pool2d\",\"aten::max_pool2d_with_indices\"],\"percentage\":{\"__ndarray__\":\"UrgehesRMUBSuB6F6xExQFK4HoXrETFAUrgehesRMUApXI/C9agjQNejcD0K1xVA16NwPQrXFUDXo3A9CtcVQD0K16NwPQZA7FG4HoXrBUA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[10]},\"time\":[124294963,124293439,124292181,124287727,71588153,39753213,39750598,39748190,20243406,19964167]},\"selected\":{\"id\":\"1709\"},\"selection_policy\":{\"id\":\"1710\"}},\"id\":\"1603\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1710\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1648\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"columns\":[{\"id\":\"1604\"},{\"id\":\"1605\"},{\"id\":\"1606\"}],\"height\":350,\"source\":{\"id\":\"1603\"},\"view\":{\"id\":\"1608\"},\"width\":550},\"id\":\"1607\",\"type\":\"DataTable\"},{\"attributes\":{},\"id\":\"1650\",\"type\":\"Selection\"}],\"root_ids\":[\"1655\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"29092e4f-4c6c-49cf-b6c2-2f3f3e504800\",\"root_ids\":[\"1655\"],\"roots\":{\"1655\":\"bdc39357-cd88-4d97-a252-4a1dc1460f96\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1655"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "rows = [] \n",
    "values = []\n",
    "if report:\n",
    "    if 'CPU_total' in report['Details']:\n",
    "        display(Markdown(f\"\"\"#### Overview: CPU operators\"\"\"))\n",
    "        event = max(report['Details']['CPU'], key=report['Details']['CPU'].get)\n",
    "        perc = report['Details']['CPU'][event]\n",
    "\n",
    "        for function in report['Details']['CPU']:\n",
    "            percentage = round(report['Details']['CPU'][function],2)\n",
    "            time = report['Details']['CPU_total'][function]               \n",
    "            rows.append([percentage, time, function])\n",
    "\n",
    "        df = pd.DataFrame(rows) \n",
    "        df.columns = ['percentage', 'time', 'operator']\n",
    "\n",
    "        df = df.sort_values(by=['percentage'], ascending=False)\n",
    "        source = ColumnDataSource(data=df)\n",
    "        columns = [TableColumn(field='percentage', title=\"Percentage\"),\n",
    "                   TableColumn(field='time', title=\"Cumulative time in microseconds\"),\n",
    "                  TableColumn(field='operator', title=\"CPU operator\"),]\n",
    "\n",
    "        table = DataTable(source=source, columns=columns, width=550, height=350)\n",
    "\n",
    "        text = Paragraph(text=f\"\"\"The following table shows a list of operators that ran on the CPUs.\n",
    "        The most expensive operator on the CPUs was \"{event}\" with {int(perc)} %.\"\"\")\n",
    "\n",
    "        plot = create_piechart(report['Details']['CPU'],\n",
    "                                height=350,\n",
    "                                width=600,\n",
    "                                x1=0.2,\n",
    "                                x2=0.6,\n",
    "                                radius=0.3, \n",
    "                               )\n",
    "\n",
    "        show(column(text, row(table, plot)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.146100Z",
     "iopub.status.busy": "2022-01-20T11:12:58.145492Z",
     "iopub.status.idle": "2022-01-20T11:12:58.147964Z",
     "shell.execute_reply": "2022-01-20T11:12:58.147478Z"
    },
    "papermill": {
     "duration": 0.032932,
     "end_time": "2022-01-20T11:12:58.148066",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.115134",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "rows = [] \n",
    "values = []\n",
    "if report:\n",
    "    if 'GPU_total' in report['Details']:\n",
    "        display(Markdown(f\"\"\"#### Overview: GPU operators\"\"\"))\n",
    "        event = max(report['Details']['GPU'], key=report['Details']['GPU'].get)\n",
    "        perc = report['Details']['GPU'][event]\n",
    "\n",
    "        for function in report['Details']['GPU']:\n",
    "            percentage = round(report['Details']['GPU'][function],2)\n",
    "            time = report['Details']['GPU_total'][function]               \n",
    "            rows.append([percentage, time, function])\n",
    "\n",
    "        df = pd.DataFrame(rows) \n",
    "        df.columns = ['percentage', 'time', 'operator']\n",
    "\n",
    "        df = df.sort_values(by=['percentage'], ascending=False)\n",
    "        source = ColumnDataSource(data=df)\n",
    "        columns = [TableColumn(field='percentage', title=\"Percentage\"),\n",
    "                   TableColumn(field='time', title=\"Cumulative time in microseconds\"),\n",
    "                  TableColumn(field='operator', title=\"GPU operator\"),]\n",
    "        table = DataTable(source=source, columns=columns, width=450, height=350)\n",
    "\n",
    "        text = Paragraph(text=f\"\"\"The following table shows a list of operators that your training job ran on GPU.\n",
    "        The most expensive operator on GPU was \"{event}\" with {int(perc)} %\"\"\")\n",
    "\n",
    "        plot = create_piechart(report['Details']['GPU'],\n",
    "                                height=350,\n",
    "                                width=600,\n",
    "                                x1=0.2,\n",
    "                                x2=0.6,\n",
    "                                radius=0.3, \n",
    "                               )\n",
    "\n",
    "        show(column(text, row(table, plot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023214,
     "end_time": "2022-01-20T11:12:58.194019",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.170805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rules summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.246527Z",
     "iopub.status.busy": "2022-01-20T11:12:58.245796Z",
     "iopub.status.idle": "2022-01-20T11:12:58.247845Z",
     "shell.execute_reply": "2022-01-20T11:12:58.248230Z"
    },
    "papermill": {
     "duration": 0.03119,
     "end_time": "2022-01-20T11:12:58.248360",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.217170",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "description = {}\n",
    "description['CPUBottleneck'] = 'Checks if the CPU utilization is high and the GPU utilization is low. \\\n",
    "It might indicate CPU bottlenecks, where the GPUs are waiting for data to arrive \\\n",
    "from the CPUs. The rule evaluates the CPU and GPU utilization rates, and triggers the issue \\\n",
    "if the time spent on the CPU bottlenecks exceeds a threshold percent of the total training time. The default threshold is 50 percent.'\n",
    "description['IOBottleneck'] =  'Checks if the data I/O wait time is high and the GPU utilization is low. \\\n",
    "It might indicate IO bottlenecks where GPU is waiting for data to arrive from storage. \\\n",
    "The rule evaluates the I/O and GPU utilization rates and triggers the issue \\\n",
    "if the time spent on the IO bottlenecks exceeds a threshold percent of the total training time. The default threshold is 50 percent.'\n",
    "description['Dataloader'] = 'Checks how many data loaders are running in parallel and whether the total number is equal the number \\\n",
    "of available CPU cores. The rule triggers if number is much smaller or larger than the number of available cores. \\\n",
    "If too small, it might lead to low GPU utilization. If too large, it might impact other compute intensive operations on CPU.'\n",
    "description['GPUMemoryIncrease'] = 'Measures the average GPU memory footprint and triggers if there is a large increase.'\n",
    "description['BatchSize'] = 'Checks if GPUs are underutilized because the batch size is too small. \\\n",
    "To detect this problem, the rule analyzes the average GPU memory footprint, \\\n",
    "the CPU and the GPU utilization. '\n",
    "description['LowGPUUtilization'] = 'Checks if the GPU utilization is low or fluctuating. \\\n",
    "This can happen due to bottlenecks, blocking calls for synchronizations, \\\n",
    "or a small batch size.'\n",
    "description['MaxInitializationTime'] = 'Checks if the time spent on initialization exceeds a threshold percent of the total training time. \\\n",
    "The rule waits until the first step of training loop starts. The initialization can take longer \\\n",
    "if downloading the entire dataset from Amazon S3 in File mode. The default threshold is 20 minutes.'\n",
    "description['LoadBalancing'] = 'Detects workload balancing issues across GPUs. \\\n",
    "Workload imbalance can occur in training jobs with data parallelism. \\\n",
    "The gradients are accumulated on a primary GPU, and this GPU might be overused \\\n",
    "with regard to other GPUs, resulting in reducing the efficiency of data parallelization.'\n",
    "description['StepOutlier'] = 'Detects outliers in step duration. The step duration for forward and backward pass should be \\\n",
    "roughly the same throughout the training. If there are significant outliers, \\\n",
    "it may indicate a system stall or bottleneck issues.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.299799Z",
     "iopub.status.busy": "2022-01-20T11:12:58.299110Z",
     "iopub.status.idle": "2022-01-20T11:12:58.301498Z",
     "shell.execute_reply": "2022-01-20T11:12:58.301086Z"
    },
    "papermill": {
     "duration": 0.030227,
     "end_time": "2022-01-20T11:12:58.301604",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.271377",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "recommendation = {}\n",
    "recommendation['CPUBottleneck'] = 'Consider increasing the number of data loaders \\\n",
    "or applying data pre-fetching.'\n",
    "recommendation['IOBottleneck'] = 'Pre-fetch data or choose different file formats, such as binary formats that \\\n",
    "improve I/O performance.'\n",
    "recommendation['Dataloader'] = 'Change the number of data loader processes.'\n",
    "recommendation['GPUMemoryIncrease'] = 'Choose a larger instance type with more memory if footprint is close to maximum available memory.'\n",
    "recommendation['BatchSize'] = 'The batch size is too small, and GPUs are underutilized. Consider running on a smaller instance type or increasing the batch size.'\n",
    "recommendation['LowGPUUtilization'] = 'Check if there are bottlenecks, minimize blocking calls, \\\n",
    "change distributed training strategy, or increase the batch size.'\n",
    "recommendation['MaxInitializationTime'] = 'Initialization takes too long. \\\n",
    "If using File mode, consider switching to Pipe mode in case you are using TensorFlow framework.'\n",
    "recommendation['LoadBalancing'] = 'Choose a different distributed training strategy or \\\n",
    "a different distributed training framework.'\n",
    "recommendation['StepOutlier'] = 'Check if there are any bottlenecks (CPU, I/O) correlated to the step outliers.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.354503Z",
     "iopub.status.busy": "2022-01-20T11:12:58.353659Z",
     "iopub.status.idle": "2022-01-20T11:12:58.364291Z",
     "shell.execute_reply": "2022-01-20T11:12:58.364675Z"
    },
    "papermill": {
     "duration": 0.040411,
     "end_time": "2022-01-20T11:12:58.364806",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.324395",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The following table shows a profiling summary of the Debugger built-in rules. \n",
       "The table is sorted by the rules that triggered the most frequently. During your training job, the Dataloader rule\n",
       "was the most frequently triggered. It processed 11 datapoints and was triggered 1 times."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Recommendation</th>\n",
       "      <th>Number of times rule triggered</th>\n",
       "      <th>Number of datapoints</th>\n",
       "      <th>Rule parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Dataloader</th>\n",
       "      <td>Checks how many data loaders are running in parallel and whether the total number is equal the number of available CPU cores. The rule triggers if number is much smaller or larger than the number of available cores. If too small, it might lead to low GPU utilization. If too large, it might impact other compute intensive operations on CPU.</td>\n",
       "      <td>Change the number of data loader processes.</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>min_threshold:70<br>max_threshold:200</td>\n",
       "    </tr>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>LoadBalancing</th>\n",
       "      <td>Detects workload balancing issues across GPUs. Workload imbalance can occur in training jobs with data parallelism. The gradients are accumulated on a primary GPU, and this GPU might be overused with regard to other GPUs, resulting in reducing the efficiency of data parallelization.</td>\n",
       "      <td>Choose a different distributed training strategy or a different distributed training framework.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>threshold:0.2<br>patience:1000</td>\n",
       "    </tr>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>MaxInitializationTime</th>\n",
       "      <td>Checks if the time spent on initialization exceeds a threshold percent of the total training time. The rule waits until the first step of training loop starts. The initialization can take longer if downloading the entire dataset from Amazon S3 in File mode. The default threshold is 20 minutes.</td>\n",
       "      <td>Initialization takes too long. If using File mode, consider switching to Pipe mode in case you are using TensorFlow framework.</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>threshold:20</td>\n",
       "    </tr>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>IOBottleneck</th>\n",
       "      <td>Checks if the data I/O wait time is high and the GPU utilization is low. It might indicate IO bottlenecks where GPU is waiting for data to arrive from storage. The rule evaluates the I/O and GPU utilization rates and triggers the issue if the time spent on the IO bottlenecks exceeds a threshold percent of the total training time. The default threshold is 50 percent.</td>\n",
       "      <td>Pre-fetch data or choose different file formats, such as binary formats that improve I/O performance.</td>\n",
       "      <td>0</td>\n",
       "      <td>3232</td>\n",
       "      <td>threshold:50<br>io_threshold:50<br>gpu_threshold:10<br>patience:1000</td>\n",
       "    </tr>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>StepOutlier</th>\n",
       "      <td>Detects outliers in step duration. The step duration for forward and backward pass should be roughly the same throughout the training. If there are significant outliers, it may indicate a system stall or bottleneck issues.</td>\n",
       "      <td>Check if there are any bottlenecks (CPU, I/O) correlated to the step outliers.</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>threshold:3<br>mode:None<br>n_outliers:10<br>stddev:3</td>\n",
       "    </tr>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>LowGPUUtilization</th>\n",
       "      <td>Checks if the GPU utilization is low or fluctuating. This can happen due to bottlenecks, blocking calls for synchronizations, or a small batch size.</td>\n",
       "      <td>Check if there are bottlenecks, minimize blocking calls, change distributed training strategy, or increase the batch size.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>threshold_p95:70<br>threshold_p5:10<br>window:500<br>patience:1000</td>\n",
       "    </tr>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>GPUMemoryIncrease</th>\n",
       "      <td>Measures the average GPU memory footprint and triggers if there is a large increase.</td>\n",
       "      <td>Choose a larger instance type with more memory if footprint is close to maximum available memory.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>increase:5<br>patience:1000<br>window:10</td>\n",
       "    </tr>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>BatchSize</th>\n",
       "      <td>Checks if GPUs are underutilized because the batch size is too small. To detect this problem, the rule analyzes the average GPU memory footprint, the CPU and the GPU utilization.</td>\n",
       "      <td>The batch size is too small, and GPUs are underutilized. Consider running on a smaller instance type or increasing the batch size.</td>\n",
       "      <td>0</td>\n",
       "      <td>3226</td>\n",
       "      <td>cpu_threshold_p95:70<br>gpu_threshold_p95:70<br>gpu_memory_threshold_p95:70<br>patience:1000<br>window:500</td>\n",
       "    </tr>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>CPUBottleneck</th>\n",
       "      <td>Checks if the CPU utilization is high and the GPU utilization is low. It might indicate CPU bottlenecks, where the GPUs are waiting for data to arrive from the CPUs. The rule evaluates the CPU and GPU utilization rates, and triggers the issue if the time spent on the CPU bottlenecks exceeds a threshold percent of the total training time. The default threshold is 50 percent.</td>\n",
       "      <td>Consider increasing the number of data loaders or applying data pre-fetching.</td>\n",
       "      <td>0</td>\n",
       "      <td>3232</td>\n",
       "      <td>threshold:50<br>cpu_threshold:90<br>gpu_threshold:10<br>patience:1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = glob.glob('/opt/ml/processing/output/rule/profiler-output/profiler-reports/*json')\n",
    "summary = {}\n",
    "for i in files:\n",
    "    rule_name = i.split('/')[-1].replace('.json','')\n",
    "    if rule_name == \"OverallSystemUsage\" or rule_name == \"OverallFrameworkMetrics\":\n",
    "        continue\n",
    "    rule_report = json.load(open(i))\n",
    "    summary[rule_name] = {}\n",
    "    summary[rule_name]['Description'] = description[rule_name]\n",
    "    summary[rule_name]['Recommendation'] = recommendation[rule_name]\n",
    "    summary[rule_name]['Number of times rule triggered'] = rule_report['RuleTriggered'] \n",
    "    #summary[rule_name]['Number of violations'] = rule_report['Violations'] \n",
    "    summary[rule_name]['Number of datapoints'] = rule_report['Datapoints']\n",
    "    summary[rule_name]['Rule parameters'] = rule_report['RuleParameters']\n",
    "\n",
    "df = pd.DataFrame.from_dict(summary, orient='index')\n",
    "df = df.sort_values(by=['Number of times rule triggered'], ascending=False)\n",
    "\n",
    "\n",
    "display(Markdown(f\"\"\"The following table shows a profiling summary of the Debugger built-in rules. \n",
    "The table is sorted by the rules that triggered the most frequently. During your training job, the {df.index[0]} rule\n",
    "was the most frequently triggered. It processed {df.values[0,3]} datapoints and was triggered {df.values[0,2]} times.\"\"\"))\n",
    "\n",
    "with pd.option_context('display.colheader_justify','left'):    \n",
    "    pretty_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.418865Z",
     "iopub.status.busy": "2022-01-20T11:12:58.418161Z",
     "iopub.status.idle": "2022-01-20T11:12:58.421077Z",
     "shell.execute_reply": "2022-01-20T11:12:58.421459Z"
    },
    "papermill": {
     "duration": 0.032798,
     "end_time": "2022-01-20T11:12:58.421583",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.388785",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Analyzing the training loop\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyse_phase = \"training\"\n",
    "if job_statistics and \"initialization_in_seconds\" in job_statistics:\n",
    "    if job_statistics[\"initialization_in_seconds\"] > job_statistics[\"training_loop_duration_in_seconds\"]:\n",
    "        analyse_phase = \"initialization\"\n",
    "        time = job_statistics[\"initialization_in_seconds\"]\n",
    "        perc = job_statistics[\"initialization_%\"]\n",
    "        display(Markdown(f\"\"\"The initialization phase took {int(time)} seconds, which is {int(perc)}%*\n",
    "        of the total training time. Since the training loop has taken the most time, \n",
    "        we dive deep into the events occurring during this phase\"\"\"))\n",
    "        display(Markdown(\"\"\"## Analyzing initialization\\n\\n\"\"\"))\n",
    "    time = job_statistics[\"training_loop_duration_in_seconds\"]\n",
    "    perc = job_statistics[\"training_loop_%\"]\n",
    "    display(Markdown(f\"\"\"The training loop lasted for {int(time)} seconds which is {int(perc)}% of the training job time.\n",
    "                    Since the training loop has taken the most time, we dive deep into the events occured during this phase.\"\"\"))\n",
    "if analyse_phase == 'training':\n",
    "    display(Markdown(\"\"\"## Analyzing the training loop\\n\\n\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.473141Z",
     "iopub.status.busy": "2022-01-20T11:12:58.472520Z",
     "iopub.status.idle": "2022-01-20T11:12:58.474454Z",
     "shell.execute_reply": "2022-01-20T11:12:58.474867Z"
    },
    "papermill": {
     "duration": 0.029579,
     "end_time": "2022-01-20T11:12:58.475004",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.445425",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if analyse_phase == \"initialization\":\n",
    "    display(Markdown(\"\"\"### MaxInitializationTime\\n\\nThis rule helps to detect if the training initialization is taking too much time. \\nThe rule waits until first step is available. The rule takes the parameter `threshold` that defines how many minutes to wait for the first step to become available. Default is 20 minutes.\\nYou can run the rule locally in the following way:\n",
    "    \"\"\"))\n",
    "    \n",
    "    _ = load_report(\"MaxInitializationTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.536187Z",
     "iopub.status.busy": "2022-01-20T11:12:58.525710Z",
     "iopub.status.idle": "2022-01-20T11:12:58.566473Z",
     "shell.execute_reply": "2022-01-20T11:12:58.566068Z"
    },
    "papermill": {
     "duration": 0.067359,
     "end_time": "2022-01-20T11:12:58.566572",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.499213",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Step duration analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"b6fa1c2f-3ac5-4bd7-9241-ec69f9d6ca18\" data-root-id=\"1799\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"83e82de9-71c8-42b4-9e2e-6a67300e1dee\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1798\"}]},\"id\":\"1799\",\"type\":\"Column\"},{\"attributes\":{\"text\":\"The StepOutlier rule measures step durations and checks for outliers. The rule \\n        returns True if duration is larger than 3 times the standard deviation. The rule \\n        also takes the parameter mode, that specifies whether steps from training or validation phase \\n        should be checked. In your processing job mode was specified as None. \\n        Typically the first step is taking significantly more time and to avoid the \\n        rule triggering immediately, one can use n_outliers to specify the number of outliers to ignore. \\n        n_outliers was set to 10.\\n        The rule analysed 81 datapoints and triggered 0 times.\\n        \",\"width\":900},\"id\":\"1798\",\"type\":\"Paragraph\"}],\"root_ids\":[\"1799\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"83e82de9-71c8-42b4-9e2e-6a67300e1dee\",\"root_ids\":[\"1799\"],\"roots\":{\"1799\":\"b6fa1c2f-3ac5-4bd7-9241-ec69f9d6ca18\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1799"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if analyse_phase == \"training\":\n",
    "    display(Markdown(\"\"\"### Step duration analysis\"\"\"))\n",
    "    report = load_report('StepOutlier')\n",
    "    if report:\n",
    "        parameters = report['RuleParameters']\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        stddev = params[3].split(':')[1]\n",
    "        mode = params[1].split(':')[1]\n",
    "        n_outlier = params[2].split(':')[1]\n",
    "        triggered = report['RuleTriggered']\n",
    "        datapoints = report['Datapoints']\n",
    "\n",
    "        text = f\"\"\"The StepOutlier rule measures step durations and checks for outliers. The rule \n",
    "        returns True if duration is larger than {stddev} times the standard deviation. The rule \n",
    "        also takes the parameter mode, that specifies whether steps from training or validation phase \n",
    "        should be checked. In your processing job mode was specified as {mode}. \n",
    "        Typically the first step is taking significantly more time and to avoid the \n",
    "        rule triggering immediately, one can use n_outliers to specify the number of outliers to ignore. \n",
    "        n_outliers was set to {n_outlier}.\n",
    "        The rule analysed {datapoints} datapoints and triggered {triggered} times.\n",
    "        \"\"\"\n",
    "\n",
    "        paragraph = Paragraph(text=text, width=900)\n",
    "        show(column(paragraph))\n",
    "\n",
    "        if report and len(report['Details']['step_details']) > 0:\n",
    "            for node_id in report['Details']['step_details']:\n",
    "                tmp = report['RuleParameters'].split('threshold:')\n",
    "                threshold = tmp[1].split('\\n')[0]\n",
    "                n_outliers = report['Details']['step_details'][node_id]['number_of_outliers']\n",
    "                mean = report['Details']['step_details'][node_id]['step_stats']['mean']\n",
    "                stddev = report['Details']['step_details'][node_id]['stddev']\n",
    "                phase = report['Details']['step_details'][node_id]['phase']\n",
    "                display(Markdown(f\"\"\"**Step durations on node {node_id}:**\"\"\"))\n",
    "                display(Markdown(f\"\"\"The following table is a summary of the statistics of step durations measured on node {node_id}.\n",
    "                The rule has analyzed the step duration from {phase} phase.\n",
    "                The average step duration on node {node_id} was {round(mean, 2)}s. \n",
    "                The rule detected {n_outliers} outliers, where step duration was larger than {threshold} times the standard deviation of {stddev}s\n",
    "                                 \\n\"\"\"))\n",
    "                step_stats_df = pd.DataFrame.from_dict(report['Details']['step_details'][node_id]['step_stats'], orient='index').T\n",
    "                step_stats_df.index = ['Step Durations in [s]']\n",
    "                pretty_print(step_stats_df)\n",
    "\n",
    "            display(Markdown(f\"\"\"The following histogram shows the step durations measured on the different nodes. \n",
    "                You can turn on or turn off the visualization of histograms by selecting or unselecting the labels in the legend.\"\"\"))\n",
    "\n",
    "            plot = figure(plot_height=450, \n",
    "                              plot_width=850, \n",
    "                              title=f\"\"\"Step durations\"\"\")  \n",
    "\n",
    "            colors = bokeh.palettes.viridis(len(report['Details']['step_details']))\n",
    "\n",
    "            for index, node_id in enumerate(report['Details']['step_details']):\n",
    "                probs = report['Details']['step_details'][node_id]['probs']\n",
    "                binedges = report['Details']['step_details'][node_id]['binedges']\n",
    "\n",
    "                plot.quad( top=probs,\n",
    "                        bottom=0,\n",
    "                        left=binedges[:-1],\n",
    "                        right=binedges[1:],\n",
    "                        line_color=\"white\",\n",
    "                        fill_color=colors[index],\n",
    "                        fill_alpha=0.7,\n",
    "                        legend=node_id)\n",
    "\n",
    "            plot.add_layout(Legend(), 'right')    \n",
    "            plot.y_range.start = 0\n",
    "            plot.xaxis.axis_label = f\"\"\"Step durations in [s]\"\"\"\n",
    "            plot.yaxis.axis_label = \"Occurrences\"\n",
    "            plot.grid.grid_line_color = \"white\"\n",
    "            plot.legend.click_policy=\"hide\"\n",
    "            plot.legend.location = 'center_right'\n",
    "            show(plot)\n",
    "\n",
    "        if report['RuleTriggered'] > 0:\n",
    "\n",
    "            text=f\"\"\"To get a better understanding of what may have caused those outliers,\n",
    "            we correlate the timestamps of step outliers with other framework metrics that happened at the same time.\n",
    "            The left chart shows how much time was spent in the different framework\n",
    "            metrics aggregated by event phase. The chart on the right shows the histogram of normal step durations (without\n",
    "            outliers). The following chart shows how much time was spent in the different \n",
    "            framework metrics when step outliers occurred. In this chart framework metrics are not aggregated byphase.\"\"\"\n",
    "            plots = []\n",
    "            if 'phase' in report['Details']:\n",
    "                text = f\"\"\"{text} The chart (in the middle) shows whether step outliers mainly happened during TRAIN or EVAL phase.\n",
    "                \"\"\"\n",
    "\n",
    "                plot = create_piechart(report['Details']['phase'], \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"The ratio between the time spent on the TRAIN/EVAL phase\")\n",
    "                plots.append(plot)\n",
    "\n",
    "            if 'forward_backward' in report['Details'] and  len(report['Details']['forward_backward']) > 0:\n",
    "\n",
    "                event = max(report['Details']['forward_backward'], key=report['Details']['forward_backward'].get)\n",
    "                perc = report['Details']['forward_backward'][event]\n",
    "\n",
    "                text = f\"\"\"{text} The pie chart on the right shows a detailed breakdown. \n",
    "                It shows that {int(perc)}% of the training time was spent on event \"{event}\".\"\"\"\n",
    "\n",
    "                plot = create_piechart(report['Details']['forward_backward'], \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"The Ratio between forward and backward pass\") \n",
    "                plots.append(plot)\n",
    "\n",
    "            if len(plots) > 0:\n",
    "                paragraph = Paragraph(text=text, width=900)\n",
    "                show(column(paragraph, row(plots)))\n",
    "\n",
    "            plots = []\n",
    "            text = \"\"\n",
    "            if 'ratio' in report['Details'] and len(report['Details']['ratio']) > 0:\n",
    "\n",
    "                key = list(report['Details']['ratio'].keys())[0]\n",
    "                ratio = report['Details']['ratio'][key]\n",
    "\n",
    "                text = f\"\"\"The following pie chart shows a breakdown of the CPU/GPU operators executed during the step outliers. \n",
    "                    It shows that {int(ratio)}% of the training time was spent on executing operators in \"{key}\".\"\"\"\n",
    "\n",
    "                plot = create_piechart(report['Details']['ratio'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"The ratio between CPU/GPU operators\")\n",
    "                plots.append(plot)\n",
    "\n",
    "\n",
    "            if 'general' in report['Details'] and len(report['Details']['general']) > 0:\n",
    "\n",
    "                event = max(report['Details']['general'], key=report['Details']['general'].get)\n",
    "                perc = report['Details']['general'][event]\n",
    "\n",
    "                plot = create_piechart(report['Details']['general'], \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"General metrics recorded in framework \")\n",
    "                plots.append(plot)\n",
    "\n",
    "            if len(plots) > 0:\n",
    "                paragraph = Paragraph(text=text, width=900)\n",
    "                show(column(paragraph, row(plots)))\n",
    "\n",
    "            plots = []\n",
    "            text = \"\"\n",
    "            if 'horovod' in report['Details'] and len(report['Details']['horovod']) > 0:\n",
    "\n",
    "                event = max(report['Details']['horovod'], key=report['Details']['horovod'].get)\n",
    "                perc = report['Details']['horovod'][event]\n",
    "                text = f\"\"\"The following pie chart shows a detailed breakdown of the Horovod metrics that have been\n",
    "                recorded when step outliers happened. The most expensive function was {event} with {int(perc)}%\"\"\"\n",
    "\n",
    "                plot = create_piechart(report['Details']['horovod'], \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"General metrics recorded in framework \")\n",
    "\n",
    "                paragraph = Paragraph(text=text, width=900)\n",
    "                show(column(paragraph, row(plot)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.635182Z",
     "iopub.status.busy": "2022-01-20T11:12:58.630594Z",
     "iopub.status.idle": "2022-01-20T11:12:58.653472Z",
     "shell.execute_reply": "2022-01-20T11:12:58.653858Z"
    },
    "papermill": {
     "duration": 0.062332,
     "end_time": "2022-01-20T11:12:58.653992",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.591660",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### GPU utilization analysis\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Usage per GPU** \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"76f0399c-9c7b-4316-b417-1dc04097246e\" data-root-id=\"1867\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"60be6852-285f-41eb-a7a8-250f8c58b251\":{\"roots\":{\"references\":[{\"attributes\":{\"text\":\"The LowGPUUtilization rule checks for a low and fluctuating GPU usage. If the GPU usage is \\n        consistently low, it might be caused by bottlenecks or a small batch size. If usage is heavily \\n        fluctuating, it can be due to bottlenecks or blocking calls. The rule computed the 95th and 5th \\n        percentile of GPU utilization on 500 continuous datapoints and found 0 cases where \\n        p95 was above 70% and p5 was below 10%. If p95 is high and p5 is low,\\n        it might indicate that the GPU usage is highly fluctuating. If both values are very low, \\n        it would mean that the machine is underutilized. During initialization, the GPU usage is likely zero, \\n        so the rule skipped the first 1000 data points.\\n        The rule analysed 0 datapoints and triggered 0 times.\",\"width\":800},\"id\":\"1867\",\"type\":\"Paragraph\"}],\"root_ids\":[\"1867\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"60be6852-285f-41eb-a7a8-250f8c58b251\",\"root_ids\":[\"1867\"],\"roots\":{\"1867\":\"76f0399c-9c7b-4316-b417-1dc04097246e\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1867"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if analyse_phase == \"training\":\n",
    "    display(Markdown(\"\"\"### GPU utilization analysis\\n\\n\"\"\"))\n",
    "    display(Markdown(\"\"\"**Usage per GPU** \\n\\n\"\"\"))\n",
    "    report = load_report('LowGPUUtilization')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        threshold_p95 = params[0].split(':')[1]\n",
    "        threshold_p5 = params[1].split(':')[1]\n",
    "        window = params[2].split(':')[1]\n",
    "        patience = params[3].split(':')[1]\n",
    "        violations = report['Violations']\n",
    "        triggered = report['RuleTriggered']\n",
    "        datapoints = report['Datapoints']\n",
    "        \n",
    "        text=Paragraph(text=f\"\"\"The LowGPUUtilization rule checks for a low and fluctuating GPU usage. If the GPU usage is \n",
    "        consistently low, it might be caused by bottlenecks or a small batch size. If usage is heavily \n",
    "        fluctuating, it can be due to bottlenecks or blocking calls. The rule computed the 95th and 5th \n",
    "        percentile of GPU utilization on {window} continuous datapoints and found {violations} cases where \n",
    "        p95 was above {threshold_p95}% and p5 was below {threshold_p5}%. If p95 is high and p5 is low,\n",
    "        it might indicate that the GPU usage is highly fluctuating. If both values are very low, \n",
    "        it would mean that the machine is underutilized. During initialization, the GPU usage is likely zero, \n",
    "        so the rule skipped the first {patience} data points.\n",
    "        The rule analysed {datapoints} datapoints and triggered {triggered} times.\"\"\", width=800)\n",
    "        show(text)\n",
    "\n",
    "        \n",
    "        if len(report['Details']) > 0:\n",
    "            \n",
    "            timestamp = us_since_epoch_to_human_readable_time(report['Details']['last_timestamp'])\n",
    "            date = datetime.datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "            day = date.date().strftime(\"%m/%d/%Y\")\n",
    "            hour = date.time().strftime(\"%H:%M:%S\")\n",
    "            text = Paragraph(text=f\"\"\"Your training job is underutilizing the instance. You may want to consider\n",
    "            to either switch to a smaller instance type or to increase the batch size. \n",
    "            The last time that the LowGPUUtilization rule was triggered in your training job was on {day} at {hour}.\n",
    "            The following boxplots are a snapshot from the timestamps. \n",
    "            They show the utilization per GPU (without outliers).\n",
    "            To get a better understanding of the workloads throughout the whole training,\n",
    "            you can check the workload histogram in the next section.\"\"\", width=800)\n",
    "            show(text)\n",
    "            \n",
    "            del report['Details']['last_timestamp']\n",
    "            \n",
    "            for node_id in report['Details']:\n",
    "                \n",
    "                plot = figure(plot_height=350, \n",
    "                          plot_width=1000,\n",
    "                          toolbar_location='right',\n",
    "                          tools=\"hover,wheel_zoom,reset,pan\", \n",
    "                          title=f\"Node {node_id}\",\n",
    "                          x_range=(0,17),\n",
    "                          )\n",
    "                \n",
    "                for index, key in enumerate(report['Details'][node_id]):\n",
    "                    display(Markdown(f\"\"\"**GPU utilization of {key} on node {node_id}:**\"\"\"))\n",
    "                    text = \"\"\n",
    "                    gpu_max = report['Details'][node_id][key]['gpu_max']\n",
    "                    p_95 = report['Details'][node_id][key]['gpu_95']\n",
    "                    p_5 = report['Details'][node_id][key]['gpu_5']\n",
    "                    text = f\"\"\"{text} The max utilization of {key} on node {node_id} was {gpu_max}%\"\"\"\n",
    "                    if p_95 < int(threshold_p95): \n",
    "                        text = f\"\"\"{text} and the 95th percentile was only {p_95}%. \n",
    "                        {key} on node {node_id} is underutilized\"\"\"\n",
    "                    if p_5 < int(threshold_p5): \n",
    "                        text = f\"\"\"{text} and the 5th percentile was only {p_5}%\"\"\"\n",
    "                    if p_95 - p_5 > 50:\n",
    "                        text = f\"\"\"{text} The difference between 5th percentile {p_5}% and 95th percentile {p_95}% is quite \n",
    "                        significant, which means that utilization on {key} is fluctuating quite a lot.\\n\"\"\"\n",
    "     \n",
    "                    upper = report['Details'][node_id][key]['upper']\n",
    "                    lower = report['Details'][node_id][key]['lower']\n",
    "                    p75 = report['Details'][node_id][key]['p75']\n",
    "                    p25 = report['Details'][node_id][key]['p25']\n",
    "                    p50 = report['Details'][node_id][key]['p50']\n",
    "\n",
    "                    plot.segment(index+1, upper, index+1, p75, line_color=\"black\")\n",
    "                    plot.segment(index+1, lower, index+1, p25, line_color=\"black\")\n",
    "\n",
    "                    plot.vbar(index+1, 0.7, p50, p75, fill_color=\"#FDE725\", line_color=\"black\")\n",
    "                    plot.vbar(index+1, 0.7, p25, p50, fill_color=\"#440154\", line_color=\"black\")\n",
    "\n",
    "                    plot.rect(index+1, lower, 0.2, 0.01, line_color=\"black\")\n",
    "                    plot.rect(index+1, upper, 0.2, 0.01, line_color=\"black\")\n",
    "\n",
    "                    plot.xaxis.major_label_overrides[index+1] = key\n",
    "                    plot.xgrid.grid_line_color = None\n",
    "                    plot.ygrid.grid_line_color = \"white\"\n",
    "                    plot.grid.grid_line_width = 0\n",
    "\n",
    "                    plot.xaxis.major_label_text_font_size=\"10px\"\n",
    "                    text=Paragraph(text=f\"\"\"{text}\"\"\", width=900)\n",
    "                    show(text)\n",
    "                plot.yaxis.axis_label = \"Utilization in %\"\n",
    "                plot.xaxis.ticker = np.arange(index+2)\n",
    "                \n",
    "                show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.720076Z",
     "iopub.status.busy": "2022-01-20T11:12:58.719290Z",
     "iopub.status.idle": "2022-01-20T11:12:58.737279Z",
     "shell.execute_reply": "2022-01-20T11:12:58.736869Z"
    },
    "papermill": {
     "duration": 0.05647,
     "end_time": "2022-01-20T11:12:58.737386",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.680916",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Workload balancing**\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"4e85352b-6fa6-4f38-ab0e-5427ec55f93d\" data-root-id=\"1935\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"1e25ea5a-e3d9-423a-ba82-65a4df0eebdb\":{\"roots\":{\"references\":[{\"attributes\":{\"text\":\"The LoadBalancing rule helps to detect issues in workload balancing \\n        between multiple GPUs. \\n        It computes a histogram of GPU utilization values for each GPU and compares then the \\n        similarity between histograms. The rule checked if the distance of histograms is larger than the \\n        threshold of 0.2.\\n        During initialization utilization is likely zero, so the rule skipped the first 1000 data points.\\n        \",\"width\":900},\"id\":\"1935\",\"type\":\"Paragraph\"}],\"root_ids\":[\"1935\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"1e25ea5a-e3d9-423a-ba82-65a4df0eebdb\",\"root_ids\":[\"1935\"],\"roots\":{\"1935\":\"4e85352b-6fa6-4f38-ab0e-5427ec55f93d\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1935"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "if analyse_phase == \"training\": \n",
    "    display(Markdown(\"\"\"**Workload balancing**\\n\\n\"\"\")) \n",
    "    report = load_report('LoadBalancing')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        threshold = params[0].split(':')[1]\n",
    "        patience = params[1].split(':')[1]\n",
    "        triggered = report['RuleTriggered']\n",
    "        datapoints = report['Datapoints']\n",
    "    \n",
    "        paragraph = Paragraph(text=f\"\"\"The LoadBalancing rule helps to detect issues in workload balancing \n",
    "        between multiple GPUs. \n",
    "        It computes a histogram of GPU utilization values for each GPU and compares then the \n",
    "        similarity between histograms. The rule checked if the distance of histograms is larger than the \n",
    "        threshold of {threshold}.\n",
    "        During initialization utilization is likely zero, so the rule skipped the first {patience} data points.\n",
    "        \"\"\", width=900)\n",
    "        show(paragraph)\n",
    "        \n",
    "        if len(report['Details']) > 0:\n",
    "            for node_id in report['Details']: \n",
    "                \n",
    "                \n",
    "                text = f\"\"\"The following histogram shows the workload per GPU on node {node_id}. \n",
    "                You can enable/disable the visualization of a workload by clicking on the label in the legend.\n",
    "                \"\"\"\n",
    "                if len(report['Details']) == 1 and len(report['Details'][node_id]['workloads']) == 1:\n",
    "                    text = f\"\"\"{text} Your training job only used one GPU so there is no workload balancing issue.\"\"\"\n",
    "                \n",
    "                plot = figure(plot_height=450, \n",
    "                              plot_width=850, \n",
    "                              x_range=(-1,100),\n",
    "                              title=f\"\"\"Workloads on node {node_id}\"\"\")\n",
    "                \n",
    "                colors = bokeh.palettes.viridis(len(report['Details'][node_id]['workloads']))\n",
    "                \n",
    "                for index, gpu_id2 in enumerate(report['Details'][node_id]['workloads']):\n",
    "                    probs = report['Details'][node_id]['workloads'][gpu_id2]\n",
    "                    plot.quad( top=probs,\n",
    "                                bottom=0,\n",
    "                                left=np.arange(0,98,2),\n",
    "                                right=np.arange(2,100,2),\n",
    "                                line_color=\"white\",\n",
    "                                fill_color=colors[index],\n",
    "                                fill_alpha=0.8,\n",
    "                                legend=gpu_id2 )\n",
    "\n",
    "                    plot.y_range.start = 0\n",
    "                    plot.xaxis.axis_label = f\"\"\"Utilization\"\"\"\n",
    "                    plot.yaxis.axis_label = \"Occurrences\"\n",
    "                    plot.grid.grid_line_color = \"white\"\n",
    "                    plot.legend.click_policy=\"hide\"\n",
    "                \n",
    "                paragraph = Paragraph(text=text)\n",
    "                show(column(paragraph, plot))\n",
    "                \n",
    "                if \"distances\" in report['Details'][node_id]:\n",
    "                    text = f\"\"\"The rule identified workload balancing issues on node {node_id} \n",
    "                    where workloads differed by more than threshold {threshold}. \n",
    "                    \"\"\"\n",
    "                    for index, gpu_id2 in enumerate(report['Details'][node_id]['distances']):\n",
    "                        for gpu_id1 in report['Details'][node_id]['distances'][gpu_id2]:\n",
    "                            distance = round(report['Details'][node_id]['distances'][gpu_id2][gpu_id1], 2)\n",
    "                            text = f\"\"\"{text} The difference of workload between {gpu_id2} and {gpu_id1} is: {distance}.\"\"\"\n",
    "\n",
    "                    paragraph = Paragraph(text=f\"\"\"{text}\"\"\", width=900)\n",
    "                    show(column(paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.804712Z",
     "iopub.status.busy": "2022-01-20T11:12:58.799331Z",
     "iopub.status.idle": "2022-01-20T11:12:58.866206Z",
     "shell.execute_reply": "2022-01-20T11:12:58.866582Z"
    },
    "papermill": {
     "duration": 0.102028,
     "end_time": "2022-01-20T11:12:58.866701",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.764673",
     "status": "completed"
    },
    "scrolled": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Dataloading analysis\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"a9937d10-c2be-4c4b-ad52-bd2be76ca0a8\" data-root-id=\"2003\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"ea7dbfda-75e4-4fad-b258-d91517578882\":{\"roots\":{\"references\":[{\"attributes\":{\"text\":\"The number of dataloader workers can greatly affect the overall performance \\n        of your training job. The rule analyzed the number of dataloading processes that have been running in \\n        parallel on the training instance and compares it against the total number of cores. \\n        The rule checked if the number of processes is smaller than 70% or larger than \\n        200% the total number of cores. Having too few dataloader workers can slowdown data preprocessing and lead to GPU \\n        underutilization. Having too many dataloader workers may hurt the\\n        overall performance if you are running other compute intensive tasks on the CPU.\\n        The rule analysed 11 datapoints and triggered 1 times.\",\"width\":900},\"id\":\"2003\",\"type\":\"Paragraph\"}],\"root_ids\":[\"2003\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"ea7dbfda-75e4-4fad-b258-d91517578882\",\"root_ids\":[\"2003\"],\"roots\":{\"2003\":\"a9937d10-c2be-4c4b-ad52-bd2be76ca0a8\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "2003"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"eda0b89f-c90d-4de7-a9fd-ef48696d937b\" data-root-id=\"2071\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"5c75fb1a-9281-4929-aff3-62ecd7209b41\":{\"roots\":{\"references\":[{\"attributes\":{\"text\":\" Your training instance provided 4 CPU cores, however your training job only \\n                ran on average 1 dataloader workers in parallel. We recommend you to increase the number of\\n                dataloader workers. Using pinned memory also improves performance because it enables fast data transfer to CUDA-enabled GPUs.\\n            The rule detected that your training job was not using pinned memory. \\n            In case of using PyTorch Dataloader, you can enable this by setting pin_memory=True.\",\"width\":900},\"id\":\"2071\",\"type\":\"Paragraph\"}],\"root_ids\":[\"2071\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"5c75fb1a-9281-4929-aff3-62ecd7209b41\",\"root_ids\":[\"2071\"],\"roots\":{\"2071\":\"eda0b89f-c90d-4de7-a9fd-ef48696d937b\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "2071"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"943a8f4b-5530-4c7c-83e3-96538b9938ad\" data-root-id=\"2181\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"9780234a-c03d-457b-8035-08e2db8273ec\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"2180\"},{\"id\":\"2139\"}]},\"id\":\"2181\",\"type\":\"Column\"},{\"attributes\":{\"below\":[{\"id\":\"2148\"}],\"center\":[{\"id\":\"2151\"},{\"id\":\"2155\"},{\"id\":\"2178\"}],\"left\":[{\"id\":\"2152\"}],\"plot_height\":450,\"plot_width\":850,\"renderers\":[{\"id\":\"2168\"}],\"title\":{\"id\":\"2171\"},\"toolbar\":{\"id\":\"2160\"},\"x_range\":{\"id\":\"2140\"},\"x_scale\":{\"id\":\"2144\"},\"y_range\":{\"id\":\"2142\"},\"y_scale\":{\"id\":\"2146\"}},\"id\":\"2139\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"2172\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"2176\",\"type\":\"Selection\"},{\"attributes\":{\"axis\":{\"id\":\"2148\"},\"grid_line_color\":\"white\",\"ticker\":null},\"id\":\"2151\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"2158\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"2146\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"2159\",\"type\":\"PanTool\"},{\"attributes\":{\"label\":{\"value\":\"Dataloading events\"},\"renderers\":[{\"id\":\"2168\"}]},\"id\":\"2179\",\"type\":\"LegendItem\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"2156\"},{\"id\":\"2157\"},{\"id\":\"2158\"},{\"id\":\"2159\"}]},\"id\":\"2160\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"2157\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"source\":{\"id\":\"2165\"}},\"id\":\"2169\",\"type\":\"CDSView\"},{\"attributes\":{\"axis_label\":\"Dataloading in [s]\",\"formatter\":{\"id\":\"2174\"},\"ticker\":{\"id\":\"2149\"}},\"id\":\"2148\",\"type\":\"LinearAxis\"},{\"attributes\":{\"text\":\"The following histogram shows the distribution of dataloading times that have been measured throughout your training job. The median dataloading time was 6.6796s. \\n            The 95th percentile was 7.011s and the 25th percentile was 6.3394s\",\"width\":900},\"id\":\"2180\",\"type\":\"Paragraph\"},{\"attributes\":{},\"id\":\"2149\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"2153\",\"type\":\"BasicTicker\"},{\"attributes\":{\"click_policy\":\"hide\",\"items\":[{\"id\":\"2179\"}]},\"id\":\"2178\",\"type\":\"Legend\"},{\"attributes\":{\"start\":0},\"id\":\"2142\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"2144\",\"type\":\"LinearScale\"},{\"attributes\":{\"end\":7.059926,\"start\":6.029856},\"id\":\"2140\",\"type\":\"Range1d\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.8},\"fill_color\":{\"value\":\"#440154\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"white\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"2166\",\"type\":\"Quad\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#440154\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"white\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"2167\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"2177\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"axis\":{\"id\":\"2152\"},\"dimension\":1,\"grid_line_color\":\"white\",\"ticker\":null},\"id\":\"2155\",\"type\":\"Grid\"},{\"attributes\":{\"text\":\"\"},\"id\":\"2171\",\"type\":\"Title\"},{\"attributes\":{\"axis_label\":\"Occurrences\",\"formatter\":{\"id\":\"2172\"},\"ticker\":{\"id\":\"2153\"}},\"id\":\"2152\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"2165\"},\"glyph\":{\"id\":\"2166\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"2167\"},\"selection_glyph\":null,\"view\":{\"id\":\"2169\"}},\"id\":\"2168\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"2174\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data\":{\"left\":[6.029856,6.0401567,6.0504574,6.060758099999999,6.071058799999999,6.0813595,6.0916602,6.1019609,6.1122616,6.122562299999999,6.1328629999999995,6.1431637,6.1534644,6.1637651,6.174065799999999,6.184366499999999,6.1946672,6.2049679,6.2152686,6.2255693,6.235869999999999,6.2461706999999995,6.2564714,6.2667721,6.2770728,6.287373499999999,6.2976741999999994,6.3079749,6.3182756,6.3285763,6.338877,6.349177699999999,6.3594783999999995,6.3697791,6.3800798,6.3903805,6.400681199999999,6.4109818999999995,6.4212826,6.4315833,6.441884,6.4521847,6.462485399999999,6.4727860999999995,6.4830868,6.4933875,6.5036882,6.5139889,6.5242895999999995,6.5345903,6.544891,6.5551917,6.5654924,6.5757931,6.5860937999999996,6.5963945,6.6066952,6.6169959,6.6272966,6.6375972999999995,6.647898,6.6581987,6.6684994,6.6788001,6.6891008,6.6994015,6.7097022,6.7200029,6.7303036,6.7406043,6.7509049999999995,6.7612057,6.7715064,6.7818071,6.7921078,6.8024085,6.8127092,6.8230099,6.8333106,6.8436113,6.853912,6.8642126999999995,6.8745134,6.8848141,6.8951148,6.9054155,6.9157162,6.9260169,6.9363176,6.9466183,6.956919,6.9672197,6.9775203999999995,6.9878211,6.9981218,7.0084225,7.0187232,7.0290239,7.0393246000000005,7.0496253],\"right\":[6.0401567,6.0504574,6.060758099999999,6.071058799999999,6.0813595,6.0916602,6.1019609,6.1122616,6.122562299999999,6.1328629999999995,6.1431637,6.1534644,6.1637651,6.174065799999999,6.184366499999999,6.1946672,6.2049679,6.2152686,6.2255693,6.235869999999999,6.2461706999999995,6.2564714,6.2667721,6.2770728,6.287373499999999,6.2976741999999994,6.3079749,6.3182756,6.3285763,6.338877,6.349177699999999,6.3594783999999995,6.3697791,6.3800798,6.3903805,6.400681199999999,6.4109818999999995,6.4212826,6.4315833,6.441884,6.4521847,6.462485399999999,6.4727860999999995,6.4830868,6.4933875,6.5036882,6.5139889,6.5242895999999995,6.5345903,6.544891,6.5551917,6.5654924,6.5757931,6.5860937999999996,6.5963945,6.6066952,6.6169959,6.6272966,6.6375972999999995,6.647898,6.6581987,6.6684994,6.6788001,6.6891008,6.6994015,6.7097022,6.7200029,6.7303036,6.7406043,6.7509049999999995,6.7612057,6.7715064,6.7818071,6.7921078,6.8024085,6.8127092,6.8230099,6.8333106,6.8436113,6.853912,6.8642126999999995,6.8745134,6.8848141,6.8951148,6.9054155,6.9157162,6.9260169,6.9363176,6.9466183,6.956919,6.9672197,6.9775203999999995,6.9878211,6.9981218,7.0084225,7.0187232,7.0290239,7.0393246000000005,7.0496253,7.059926],\"top\":[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1]},\"selected\":{\"id\":\"2176\"},\"selection_policy\":{\"id\":\"2177\"}},\"id\":\"2165\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null},\"id\":\"2156\",\"type\":\"HoverTool\"}],\"root_ids\":[\"2181\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"9780234a-c03d-457b-8035-08e2db8273ec\",\"root_ids\":[\"2181\"],\"roots\":{\"2181\":\"943a8f4b-5530-4c7c-83e3-96538b9938ad\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "2181"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if analyse_phase == \"training\":\n",
    "    display(Markdown(\"\"\"### Dataloading analysis\\n\\n\"\"\"))\n",
    "    report = load_report('Dataloader')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split(\"\\n\")\n",
    "        min_threshold = params[0].split(':')[1]\n",
    "        max_threshold = params[1].split(':')[1]\n",
    "        triggered = report['RuleTriggered']\n",
    "        datapoints = report['Datapoints']\n",
    "    \n",
    "        text=f\"\"\"The number of dataloader workers can greatly affect the overall performance \n",
    "        of your training job. The rule analyzed the number of dataloading processes that have been running in \n",
    "        parallel on the training instance and compares it against the total number of cores. \n",
    "        The rule checked if the number of processes is smaller than {min_threshold}% or larger than \n",
    "        {max_threshold}% the total number of cores. Having too few dataloader workers can slowdown data preprocessing and lead to GPU \n",
    "        underutilization. Having too many dataloader workers may hurt the\n",
    "        overall performance if you are running other compute intensive tasks on the CPU.\n",
    "        The rule analysed {datapoints} datapoints and triggered {triggered} times.\"\"\"\n",
    "        \n",
    "        paragraph = Paragraph(text=f\"{text}\", width=900)\n",
    "        show(paragraph)\n",
    "        text = \"\"\n",
    "        if 'cores' in report['Details']:\n",
    "            cores = int(report['Details']['cores'])\n",
    "            dataloaders = report['Details']['dataloaders']\n",
    "            if dataloaders < cores: \n",
    "                text=f\"\"\"{text} Your training instance provided {cores} CPU cores, however your training job only \n",
    "                ran on average {dataloaders} dataloader workers in parallel. We recommend you to increase the number of\n",
    "                dataloader workers.\"\"\"\n",
    "            if dataloaders > cores:\n",
    "                text=f\"\"\"{text} Your training instance provided {cores} CPU cores, however your training job ran \n",
    "                on average {dataloaders} dataloader workers. We recommed you to decrease the number of dataloader\n",
    "                workers.\"\"\"\n",
    "        if 'pin_memory' in report['Details'] and report['Details']['pin_memory'] == False:\n",
    "            text=f\"\"\"{text} Using pinned memory also improves performance because it enables fast data transfer to CUDA-enabled GPUs.\n",
    "            The rule detected that your training job was not using pinned memory. \n",
    "            In case of using PyTorch Dataloader, you can enable this by setting pin_memory=True.\"\"\"\n",
    "            \n",
    "        if 'prefetch' in report['Details'] and report['Details']['prefetch'] == False:\n",
    "            text=f\"\"\"{text} It appears that your training job did not perform any data pre-fetching. Pre-fetching can improve your\n",
    "            data input pipeline as it produces the data ahead of time.\"\"\"\n",
    "        paragraph = Paragraph(text=f\"{text}\", width=900)\n",
    "        show(paragraph)\n",
    "        \n",
    "        colors=bokeh.palettes.viridis(10)\n",
    "        if \"dataloading_time\" in report['Details']:\n",
    "            median = round(report['Details'][\"dataloading_time\"]['p50'],4)\n",
    "            p95 = round(report['Details'][\"dataloading_time\"]['p95'],4)\n",
    "            p25 = round(report['Details'][\"dataloading_time\"]['p25'],4)\n",
    "            binedges = report['Details'][\"dataloading_time\"]['binedges']\n",
    "            probs = report['Details'][\"dataloading_time\"]['probs']\n",
    "            text=f\"\"\"The following histogram shows the distribution of dataloading times that have been measured throughout your training job. The median dataloading time was {median}s. \n",
    "            The 95th percentile was {p95}s and the 25th percentile was {p25}s\"\"\"\n",
    "\n",
    "            plot = figure(plot_height=450, \n",
    "                              plot_width=850,\n",
    "                              toolbar_location='right',\n",
    "                              tools=\"hover,wheel_zoom,reset,pan\",\n",
    "                              x_range=(binedges[0], binedges[-1])\n",
    "                              )\n",
    "            \n",
    "            plot.quad( top=probs,\n",
    "                        bottom=0,\n",
    "                        left=binedges[:-1],\n",
    "                        right=binedges[1:],\n",
    "                        line_color=\"white\",\n",
    "                        fill_color=colors[0],\n",
    "                        fill_alpha=0.8,\n",
    "                        legend=\"Dataloading events\" )\n",
    "\n",
    "            plot.y_range.start = 0\n",
    "            plot.xaxis.axis_label = f\"\"\"Dataloading in [s]\"\"\"\n",
    "            plot.yaxis.axis_label = \"Occurrences\"\n",
    "            plot.grid.grid_line_color = \"white\"\n",
    "            plot.legend.click_policy=\"hide\"\n",
    "\n",
    "            paragraph = Paragraph(text=f\"{text}\", width=900)\n",
    "            show(column(paragraph, plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:58.939750Z",
     "iopub.status.busy": "2022-01-20T11:12:58.939241Z",
     "iopub.status.idle": "2022-01-20T11:12:58.956871Z",
     "shell.execute_reply": "2022-01-20T11:12:58.956401Z"
    },
    "papermill": {
     "duration": 0.060754,
     "end_time": "2022-01-20T11:12:58.956971",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.896217",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " ### Batch size"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"61103228-9056-49a1-b645-75d1934972b7\" data-root-id=\"2297\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"b88db179-00b6-4dc0-8afc-7330393aad71\":{\"roots\":{\"references\":[{\"attributes\":{\"text\":\"The BatchSize rule helps to detect if GPU is underutilized because of the batch size being \\n        too small. To detect this the rule analyzes the GPU memory footprint, CPU and GPU utilization. The rule checked if the 95th percentile of CPU utilization is below cpu_threshold_p95 of \\n        70%, the 95th percentile of GPU utilization is below gpu_threshold_p95 of 70% and the 95th percentile of memory footprint         below gpu_memory_threshold_p95 of 70%. In your training job this happened 0 times.         The rule skipped the first 1000 datapoints. The rule computed the percentiles over window size of 500 continuous datapoints.\\n\\n        The rule analysed 3226 datapoints and triggered 0 times.\\n        \",\"width\":800},\"id\":\"2297\",\"type\":\"Paragraph\"}],\"root_ids\":[\"2297\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"b88db179-00b6-4dc0-8afc-7330393aad71\",\"root_ids\":[\"2297\"],\"roots\":{\"2297\":\"61103228-9056-49a1-b645-75d1934972b7\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "2297"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if analyse_phase == \"training\":\n",
    "    display(Markdown(\"\"\" ### Batch size\"\"\"))\n",
    "    report = load_report('BatchSize')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        cpu_threshold_p95 = int(params[0].split(':')[1])\n",
    "        gpu_threshold_p95 = int(params[1].split(':')[1])\n",
    "        gpu_memory_threshold_p95 = int(params[2].split(':')[1])\n",
    "        patience = int(params[3].split(':')[1])\n",
    "        window = int(params[4].split(':')[1])\n",
    "        violations = report['Violations']\n",
    "        triggered = report['RuleTriggered']\n",
    "        datapoints = report['Datapoints']\n",
    "        \n",
    "        text = Paragraph(text=f\"\"\"The BatchSize rule helps to detect if GPU is underutilized because of the batch size being \n",
    "        too small. To detect this the rule analyzes the GPU memory footprint, CPU and GPU utilization. The rule checked if the 95th percentile of CPU utilization is below cpu_threshold_p95 of \n",
    "        {cpu_threshold_p95}%, the 95th percentile of GPU utilization is below gpu_threshold_p95 of {gpu_threshold_p95}% and the 95th percentile of memory footprint \\\n",
    "        below gpu_memory_threshold_p95 of {gpu_memory_threshold_p95}%. In your training job this happened {violations} times. \\\n",
    "        The rule skipped the first {patience} datapoints. The rule computed the percentiles over window size of {window} continuous datapoints.\\n\n",
    "        The rule analysed {datapoints} datapoints and triggered {triggered} times.\n",
    "        \"\"\", width=800)\n",
    "        show(text)\n",
    "        if len(report['Details']) >0: \n",
    "            timestamp = us_since_epoch_to_human_readable_time(report['Details']['last_timestamp'])\n",
    "            date = datetime.datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "            day = date.date().strftime(\"%m/%d/%Y\")\n",
    "            hour = date.time().strftime(\"%H:%M:%S\")\n",
    "            del report['Details']['last_timestamp']\n",
    "            text = Paragraph(text=f\"\"\"Your training job is underutilizing the instance. You may want to consider\n",
    "            either switch to a smaller instance type or to increase the batch size. \n",
    "            The last time the BatchSize rule triggered in your training job was on {day} at {hour}.\n",
    "            The following boxplots are a snapshot from the timestamps. They the total \n",
    "            CPU utilization, the GPU utilization, and the GPU memory usage per GPU (without outliers).\"\"\", \n",
    "            width=800)\n",
    "            show(text)\n",
    "\n",
    "            for node_id in report['Details']:\n",
    "                xmax = max(20, len(report['Details'][node_id]))\n",
    "                \n",
    "                plot = figure(plot_height=350, \n",
    "                          plot_width=1000,\n",
    "                          toolbar_location='right',\n",
    "                          tools=\"hover,wheel_zoom,reset,pan\", \n",
    "                          title=f\"Node {node_id}\",\n",
    "                          x_range=(0,xmax)\n",
    "                          )\n",
    "                \n",
    "                for index, key in enumerate(report['Details'][node_id]):\n",
    "                        upper = report['Details'][node_id][key]['upper']\n",
    "                        lower = report['Details'][node_id][key]['lower']\n",
    "                        p75 = report['Details'][node_id][key]['p75']\n",
    "                        p25 = report['Details'][node_id][key]['p25']\n",
    "                        p50 = report['Details'][node_id][key]['p50']\n",
    "\n",
    "                        plot.segment(index+1, upper, index+1, p75, line_color=\"black\")\n",
    "                        plot.segment(index+1, lower, index+1, p25, line_color=\"black\")\n",
    "\n",
    "                        plot.vbar(index+1, 0.7, p50, p75, fill_color=\"#FDE725\", line_color=\"black\")\n",
    "                        plot.vbar(index+1, 0.7, p25, p50, fill_color=\"#440154\", line_color=\"black\")\n",
    "\n",
    "                        plot.rect(index+1, lower, 0.2, 0.01, line_color=\"black\")\n",
    "                        plot.rect(index+1, upper, 0.2, 0.01, line_color=\"black\")\n",
    "\n",
    "                        plot.xaxis.major_label_overrides[index+1] = key\n",
    "                        plot.xgrid.grid_line_color = None\n",
    "                        plot.ygrid.grid_line_color = \"white\"\n",
    "                        plot.grid.grid_line_width = 0\n",
    "\n",
    "                        plot.xaxis.major_label_text_font_size=\"10px\"\n",
    "                plot.xaxis.ticker = np.arange(index+2)\n",
    "                plot.yaxis.axis_label = \"Utilization in %\"\n",
    "                show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:59.039012Z",
     "iopub.status.busy": "2022-01-20T11:12:59.038457Z",
     "iopub.status.idle": "2022-01-20T11:12:59.055898Z",
     "shell.execute_reply": "2022-01-20T11:12:59.056274Z"
    },
    "papermill": {
     "duration": 0.069197,
     "end_time": "2022-01-20T11:12:59.056386",
     "exception": false,
     "start_time": "2022-01-20T11:12:58.987189",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### CPU bottlenecks\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"73ae5bbb-a6d0-4ae0-8363-a7c0c6b10c78\" data-root-id=\"2373\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"a27192e0-beab-4d6f-985c-5aef258c7e69\":{\"roots\":{\"references\":[{\"attributes\":{\"text\":\"The CPUBottleneck rule checked when the CPU utilization was above cpu_threshold of 90% \\n        and GPU utilization was below gpu_threshold of 10%. \\n        During initialization utilization is likely to be zero, so the rule skipped the first 1000 datapoints.\\n        With this configuration the rule found 0 CPU bottlenecks which is 0% of the total time. This is below the threshold of 50%\\n        The rule analysed 3232 data points and triggered 0 times.\",\"width\":900},\"id\":\"2373\",\"type\":\"Paragraph\"}],\"root_ids\":[\"2373\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"a27192e0-beab-4d6f-985c-5aef258c7e69\",\"root_ids\":[\"2373\"],\"roots\":{\"2373\":\"73ae5bbb-a6d0-4ae0-8363-a7c0c6b10c78\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "2373"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if analyse_phase == \"training\": \n",
    "    display(Markdown(\"\"\"### CPU bottlenecks\\n\\n\"\"\"))\n",
    "\n",
    "    report = load_report('CPUBottleneck')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        threshold = int(params[0].split(':')[1])\n",
    "        cpu_threshold = int(params[1].split(':')[1])\n",
    "        gpu_threshold = int(params[2].split(':')[1])\n",
    "        patience = int(params[3].split(':')[1])\n",
    "        violations = report['Violations']\n",
    "        triggered = report['RuleTriggered']\n",
    "        datapoints = report['Datapoints']\n",
    "        \n",
    "        if report['Violations'] > 0:\n",
    "            perc = int(report['Violations']/report['Datapoints']*100)\n",
    "        else:\n",
    "            perc = 0\n",
    "        if perc < threshold:\n",
    "            string = 'below'\n",
    "        else:\n",
    "            string = 'above'\n",
    "        text = f\"\"\"The CPUBottleneck rule checked when the CPU utilization was above cpu_threshold of {cpu_threshold}% \n",
    "        and GPU utilization was below gpu_threshold of {gpu_threshold}%. \n",
    "        During initialization utilization is likely to be zero, so the rule skipped the first {patience} datapoints.\n",
    "        With this configuration the rule found {violations} CPU bottlenecks which is {perc}% of the total time. This is {string} the threshold of {threshold}%\n",
    "        The rule analysed {datapoints} data points and triggered {triggered} times.\"\"\"\n",
    "        \n",
    "        paragraph = Paragraph(text=text, width=900)\n",
    "        show(paragraph)\n",
    "        if report:\n",
    "\n",
    "            plots = []\n",
    "            text = \"\"\n",
    "            if report['RuleTriggered'] > 0:\n",
    "\n",
    "                low_gpu = report['Details']['low_gpu_utilization']\n",
    "                cpu_bottleneck = {}\n",
    "                cpu_bottleneck[\"GPU usage above threshold\"] = report[\"Datapoints\"] - report[\"Details\"][\"low_gpu_utilization\"]\n",
    "                cpu_bottleneck[\"GPU usage below threshold\"] = report[\"Details\"][\"low_gpu_utilization\"] - len(report[\"Details\"])\n",
    "                cpu_bottleneck[\"Low GPU usage due to CPU bottlenecks\"] = len(report[\"Details\"][\"bottlenecks\"])\n",
    "\n",
    "                n_bottlenecks = round(len(report['Details']['bottlenecks'])/datapoints * 100, 2)\n",
    "                text = f\"\"\"The following chart (left) shows how many datapoints were below the gpu_threshold of {gpu_threshold}%\n",
    "                and how many of those datapoints were likely caused by a CPU bottleneck. The rule found {low_gpu} out of {datapoints} datapoints which had a GPU utilization \n",
    "                below {gpu_threshold}%. Out of those datapoints {n_bottlenecks}% were likely caused by CPU bottlenecks. \n",
    "                \"\"\"\n",
    "\n",
    "                plot = create_piechart(cpu_bottleneck, \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"Low GPU usage caused by CPU bottlenecks\")\n",
    "\n",
    "                plots.append(plot)\n",
    "\n",
    "                if 'phase' in report['Details']:\n",
    "                    text = f\"\"\"{text} The chart (in the middle) shows whether CPU bottlenecks mainly \n",
    "                    happened during train/validation phase.\n",
    "                    \"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['phase'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"The ratio between time spent on TRAIN/EVAL phase\")\n",
    "                    plots.append(plot)\n",
    "\n",
    "                if 'forward_backward' in report['Details'] and  len(report['Details']['forward_backward']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['forward_backward'], key=report['Details']['forward_backward'].get)\n",
    "                    perc = report['Details']['forward_backward'][event]\n",
    "\n",
    "                    text = f\"\"\"{text} The pie charts on the right shows a more detailed breakdown. \n",
    "                    It shows that {int(perc)}% of the training time was spent on event {event}\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['forward_backward'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"The ratio between forward and backward pass\") \n",
    "                    plots.append(plot)\n",
    "\n",
    "                if len(plots) > 0:\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plots)))\n",
    "\n",
    "                plots = []\n",
    "                text = \"\"\n",
    "                if 'ratio' in report['Details'] and len(report['Details']['ratio']) > 0:\n",
    "\n",
    "                    key = list(report['Details']['ratio'].keys())[0]\n",
    "                    ratio = report['Details']['ratio'][key]\n",
    "\n",
    "                    text = f\"\"\"The following pie chart shows a breakdown of the CPU/GPU operators that happened during CPU bottlenecks. \n",
    "                        It shows that {int(ratio)}% of the training time was spent on executing operators in \"{key}\".\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['ratio'], \n",
    "                                            height=350,\n",
    "                                            width=600,\n",
    "                                            x1=0.2,\n",
    "                                            x2=0.6,\n",
    "                                            radius=0.3, \n",
    "                                            title=\"The ratio between CPU/GPU operators\")\n",
    "                    plots.append(plot)\n",
    "\n",
    "\n",
    "                if 'general' in report['Details'] and len(report['Details']['general']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['general'], key=report['Details']['general'].get)\n",
    "                    perc = report['Details']['general'][event]\n",
    "                \n",
    "                    plot = create_piechart(report['Details']['general'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"General metrics recorded in framework \")\n",
    "                    plots.append(plot)\n",
    "\n",
    "                if len(plots) > 0:\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plots)))\n",
    "\n",
    "                plots = []\n",
    "                text = \"\"\n",
    "                if 'horovod' in report['Details'] and len(report['Details']['horovod']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['horovod'], key=report['Details']['horovod'].get)\n",
    "                    perc = report['Details']['horovod'][event]\n",
    "                    text = f\"\"\"The following pie chart shows a detailed breakdown of the Horovod metrics \n",
    "                    that have been recorded when the CPU bottleneck happened. The most expensive function was \n",
    "                    {event} with {int(perc)}%\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['horovod'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"General metrics recorded in framework \")\n",
    "\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:59.138871Z",
     "iopub.status.busy": "2022-01-20T11:12:59.130819Z",
     "iopub.status.idle": "2022-01-20T11:12:59.156395Z",
     "shell.execute_reply": "2022-01-20T11:12:59.156776Z"
    },
    "papermill": {
     "duration": 0.069414,
     "end_time": "2022-01-20T11:12:59.156887",
     "exception": false,
     "start_time": "2022-01-20T11:12:59.087473",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### I/O bottlenecks\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"504f4833-360f-4dbc-b7df-a98833b5fd69\" data-root-id=\"2449\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"f828d231-330c-4427-989e-1a1376802152\":{\"roots\":{\"references\":[{\"attributes\":{\"text\":\"The IOBottleneck rule checked when I/O wait time was above io_threshold of 50% \\n        and GPU utilization was below gpu_threshold of 10. During initialization utilization is likely to be zero, so the rule skipped the first 1000 datapoints. \\n        With this configuration the rule found 0 I/O bottlenecks which is 0% of the total time. This is below the threshold of 50%.\\n        The rule analysed 3232 datapoints and triggered 0 times.\",\"width\":900},\"id\":\"2449\",\"type\":\"Paragraph\"}],\"root_ids\":[\"2449\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"f828d231-330c-4427-989e-1a1376802152\",\"root_ids\":[\"2449\"],\"roots\":{\"2449\":\"504f4833-360f-4dbc-b7df-a98833b5fd69\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "2449"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if analyse_phase == \"training\": \n",
    "    display(Markdown(\"\"\"### I/O bottlenecks\\n\\n\"\"\"))\n",
    "\n",
    "    report = load_report('IOBottleneck')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        threshold = int(params[0].split(':')[1])\n",
    "        io_threshold = int(params[1].split(':')[1])\n",
    "        gpu_threshold = int(params[2].split(':')[1])\n",
    "        patience = int(params[3].split(':')[1])\n",
    "        violations = report['Violations']\n",
    "        triggered = report['RuleTriggered']\n",
    "        datapoints = report['Datapoints']\n",
    "    \n",
    "        if report['Violations'] > 0:\n",
    "            perc = int(report['Violations']/report['Datapoints']*100)\n",
    "        else:\n",
    "            perc = 0\n",
    "        if perc < threshold:\n",
    "            string = 'below'\n",
    "        else:\n",
    "            string = 'above'\n",
    "        text = f\"\"\"The IOBottleneck rule checked when I/O wait time was above io_threshold of {io_threshold}% \n",
    "        and GPU utilization was below gpu_threshold of {gpu_threshold}. During initialization utilization is likely to be zero, so the rule skipped the first {patience} datapoints. \n",
    "        With this configuration the rule found {violations} I/O bottlenecks which is {perc}% of the total time. This is {string} the threshold of {threshold}%.\n",
    "        The rule analysed {datapoints} datapoints and triggered {triggered} times.\"\"\"\n",
    "        paragraph = Paragraph(text=text, width=900)\n",
    "        show(paragraph)\n",
    "        \n",
    "        if report:\n",
    "\n",
    "            plots = []\n",
    "            text = \"\"\n",
    "            if report['RuleTriggered'] > 0:\n",
    "\n",
    "                low_gpu = report['Details']['low_gpu_utilization']\n",
    "                cpu_bottleneck = {}\n",
    "                cpu_bottleneck[\"GPU usage above threshold\"] = report[\"Datapoints\"] - report[\"Details\"][\"low_gpu_utilization\"]\n",
    "                cpu_bottleneck[\"GPU usage below threshold\"] = report[\"Details\"][\"low_gpu_utilization\"] - len(report[\"Details\"])\n",
    "                cpu_bottleneck[\"Low GPU usage due to I/O bottlenecks\"] = len(report[\"Details\"][\"bottlenecks\"])\n",
    "\n",
    "                n_bottlenecks = round(len(report['Details']['bottlenecks'])/datapoints * 100, 2)\n",
    "                text = f\"\"\"The following chart (left) shows how many datapoints were below the gpu_threshold of {gpu_threshold}%\n",
    "                and how many of those datapoints were likely caused by a I/O bottleneck. The rule found {low_gpu} out of {datapoints} datapoints which had a GPU utilization \n",
    "                below {gpu_threshold}%. Out of those datapoints {n_bottlenecks}% were likely caused by I/O bottlenecks. \n",
    "                \"\"\"\n",
    "\n",
    "                plot = create_piechart(cpu_bottleneck, \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"Low GPU usage caused by I/O bottlenecks\")\n",
    "\n",
    "                plots.append(plot)\n",
    "\n",
    "                if 'phase' in report['Details']:\n",
    "                    text = f\"\"\"{text} The chart (in the middle) shows whether I/O bottlenecks mainly happened during the training or validation phase.\n",
    "                    \"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['phase'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"The ratio between the time spent on the TRAIN/EVAL phase\")\n",
    "                    plots.append(plot)\n",
    "\n",
    "                if 'forward_backward' in report['Details'] and  len(report['Details']['forward_backward']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['forward_backward'], key=report['Details']['forward_backward'].get)\n",
    "                    perc = report['Details']['forward_backward'][event]\n",
    "\n",
    "                    text = f\"\"\"{text} The pie charts on the right shows a more detailed breakdown. \n",
    "                    It shows that {int(perc)}% of the training time was spent on event \"{event}\".\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['forward_backward'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"The ratio between forward and backward pass\") \n",
    "                    plots.append(plot)\n",
    "\n",
    "                if len(plots) > 0:\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plots)))\n",
    "\n",
    "                plots = []\n",
    "                text = \"\"\n",
    "                if 'ratio' in report['Details'] and len(report['Details']['ratio']) > 0:\n",
    "\n",
    "                    key = list(report['Details']['ratio'].keys())[0]\n",
    "                    ratio = report['Details']['ratio'][key]\n",
    "\n",
    "                    text = f\"\"\"The following pie chart shows a breakdown of the CPU/GPU operators that happened \n",
    "                    during I/O bottlenecks. It shows that {int(ratio)}% of the training time was spent on executing operators in \"{key}\".\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['ratio'], \n",
    "                                            height=350,\n",
    "                                            width=600,\n",
    "                                            x1=0.2,\n",
    "                                            x2=0.6,\n",
    "                                            radius=0.3, \n",
    "                                            title=\"Ratio between CPU/GPU operators\")\n",
    "                    plots.append(plot)\n",
    "\n",
    "\n",
    "                if 'general' in report['Details'] and len(report['Details']['general']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['general'], key=report['Details']['general'].get)\n",
    "                    perc = report['Details']['general'][event]\n",
    "\n",
    "                    plot = create_piechart(report['Details']['general'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"General metrics recorded in framework \")\n",
    "                    plots.append(plot)\n",
    "\n",
    "                if len(plots) > 0:\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plots)))\n",
    "\n",
    "                plots = []\n",
    "                text = \"\"\n",
    "                if 'horovod' in report['Details'] and len(report['Details']['horovod']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['horovod'], key=report['Details']['horovod'].get)\n",
    "                    perc = report['Details']['horovod'][event]\n",
    "                    text = f\"\"\"The following pie chart shows a detailed breakdown of the Horovod metrics that have been\n",
    "                    recorded when I/O bottleneck happened. The most expensive function was {event} with {int(perc)}%\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['horovod'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"General metrics recorded in framework \")\n",
    "\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plot)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:12:59.238114Z",
     "iopub.status.busy": "2022-01-20T11:12:59.237392Z",
     "iopub.status.idle": "2022-01-20T11:12:59.256241Z",
     "shell.execute_reply": "2022-01-20T11:12:59.255837Z"
    },
    "papermill": {
     "duration": 0.067436,
     "end_time": "2022-01-20T11:12:59.256338",
     "exception": false,
     "start_time": "2022-01-20T11:12:59.188902",
     "status": "completed"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### GPU memory\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"f74f3265-4ffe-4c00-ae62-0b20bbdda233\" data-root-id=\"2525\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"c3c10cb9-04e0-4ae0-b27f-8f847a92c05c\":{\"roots\":{\"references\":[{\"attributes\":{\"text\":\"The GPUMemoryIncrease rule helps to detect large increase in memory usage on GPUs. \\n        The rule checked if the moving average of memory increased by more than 5.0%. \\n        So if the moving average increased for instance from 10% to 16.0%, \\n        the rule would have triggered. During initialization utilization  is likely 0, so the rule skipped the first 1000 datapoints.\\n        The moving average was computed on a window size of 10 continuous datapoints. The rule detected 0 violations\\n        where the moving average between previous and current time window increased by more than 5.0%.\\n        The rule analysed 0 datapoints and triggered 0 times.\",\"width\":900},\"id\":\"2525\",\"type\":\"Paragraph\"}],\"root_ids\":[\"2525\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"c3c10cb9-04e0-4ae0-b27f-8f847a92c05c\",\"root_ids\":[\"2525\"],\"roots\":{\"2525\":\"f74f3265-4ffe-4c00-ae62-0b20bbdda233\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "2525"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if analyse_phase == \"training\":\n",
    "    display(Markdown(\"\"\"### GPU memory\\n\\n\"\"\"))\n",
    "    \n",
    "    report = load_report('GPUMemoryIncrease')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        increase = float(params[0].split(':')[1])\n",
    "        patience = params[1].split(':')[1]\n",
    "        window = params[2].split(':')[1]\n",
    "        violations = report['Violations']\n",
    "        triggered = report['RuleTriggered']\n",
    "        datapoints = report['Datapoints']\n",
    "    \n",
    "        text=Paragraph(text=f\"\"\"The GPUMemoryIncrease rule helps to detect large increase in memory usage on GPUs. \n",
    "        The rule checked if the moving average of memory increased by more than {increase}%. \n",
    "        So if the moving average increased for instance from 10% to {11+increase}%, \n",
    "        the rule would have triggered. During initialization utilization  is likely 0, so the rule skipped the first {patience} datapoints.\n",
    "        The moving average was computed on a window size of {window} continuous datapoints. The rule detected {violations} violations\n",
    "        where the moving average between previous and current time window increased by more than {increase}%.\n",
    "        The rule analysed {datapoints} datapoints and triggered {triggered} times.\"\"\",\n",
    "                       width=900)\n",
    "        show(text)\n",
    "\n",
    "        if len(report['Details']) > 0:\n",
    "            \n",
    "            timestamp = us_since_epoch_to_human_readable_time(report['Details']['last_timestamp'])\n",
    "            date = datetime.datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "            day = date.date().strftime(\"%m/%d/%Y\")\n",
    "            hour = date.time().strftime(\"%H:%M:%S\")\n",
    "            text = Paragraph(text=f\"\"\"Your training job triggered memory spikes. \n",
    "            The last time the GPUMemoryIncrease rule triggered in your training job was on {day} at {hour}.\n",
    "            The following boxplots are a snapshot from the timestamps. They show for each node and GPU the corresponding\n",
    "            memory utilization (without outliers).\"\"\", width=900)\n",
    "            show(text)\n",
    "            \n",
    "            del report['Details']['last_timestamp']\n",
    "            \n",
    "            for node_id in report['Details']:\n",
    "    \n",
    "                plot = figure(plot_height=350, \n",
    "                          plot_width=1000,\n",
    "                          toolbar_location='right',\n",
    "                          tools=\"hover,wheel_zoom,reset,pan\", \n",
    "                          title=f\"Node {node_id}\",\n",
    "                          x_range=(0,17),\n",
    "                          )\n",
    "\n",
    "                for index, key in enumerate(report['Details'][node_id]):\n",
    "                    display(Markdown(f\"\"\"**Memory utilization of {key} on node {node_id}:**\"\"\"))\n",
    "                    text = \"\"\n",
    "                    gpu_max = report['Details'][node_id][key]['gpu_max']\n",
    "                    text = f\"\"\"{text} The max memory utilization of {key} on node {node_id} was {gpu_max}%.\"\"\"\n",
    "                    \n",
    "                    p_95 = int(report['Details'][node_id][key]['p95'])\n",
    "                    p_5 = report['Details'][node_id][key]['p05']\n",
    "                    if p_95 < int(50): \n",
    "                        text = f\"\"\"{text} The 95th percentile was only {p_95}%.\"\"\"\n",
    "                    if p_5 < int(5): \n",
    "                        text = f\"\"\"{text} The 5th percentile was only {p_5}%.\"\"\"\n",
    "                    if p_95 - p_5 > 50:\n",
    "                        text = f\"\"\"{text} The difference between 5th percentile {p_5}% and 95th percentile {p_95}% is quite \n",
    "                        significant, which means that memory utilization on {key} is fluctuating quite a lot.\"\"\"\n",
    "                        \n",
    "                    text = Paragraph(text=f\"\"\"{text}\"\"\", width=900)\n",
    "                    show(text)\n",
    "                    \n",
    "                    upper = report['Details'][node_id][key]['upper']\n",
    "                    lower = report['Details'][node_id][key]['lower']\n",
    "                    p75 = report['Details'][node_id][key]['p75']\n",
    "                    p25 = report['Details'][node_id][key]['p25']\n",
    "                    p50 = report['Details'][node_id][key]['p50']\n",
    "\n",
    "                    plot.segment(index+1, upper, index+1, p75, line_color=\"black\")\n",
    "                    plot.segment(index+1, lower, index+1, p25, line_color=\"black\")\n",
    "\n",
    "                    plot.vbar(index+1, 0.7, p50, p75, fill_color=\"#FDE725\", line_color=\"black\")\n",
    "                    plot.vbar(index+1, 0.7, p25, p50, fill_color=\"#440154\", line_color=\"black\")\n",
    "\n",
    "                    plot.rect(index+1, lower, 0.2, 0.01, line_color=\"black\")\n",
    "                    plot.rect(index+1, upper, 0.2, 0.01, line_color=\"black\")\n",
    "\n",
    "                    plot.xaxis.major_label_overrides[index+1] = key\n",
    "                    plot.xgrid.grid_line_color = None\n",
    "                    plot.ygrid.grid_line_color = \"white\"\n",
    "                    plot.grid.grid_line_width = 0\n",
    "\n",
    "                    plot.xaxis.major_label_text_font_size=\"10px\"\n",
    "                plot.xaxis.ticker = np.arange(index+2)\n",
    "                plot.yaxis.axis_label = \"Utilization in %\"\n",
    "                show(plot)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "duration": 4.007555,
   "end_time": "2022-01-20T11:12:59.496740",
   "environment_variables": {},
   "exception": null,
   "input_path": "/opt/ml/code/profiler_report.ipynb",
   "output_path": "/opt/ml/processing/output/rule/profiler-output/.sagemaker-ignore/out.tmp",
   "parameters": {
    "processing_job_arn": "arn:aws:sagemaker:us-east-1:415073778672:processing-job/dogimageestimator-2022-01--profilerreport-39b1c02d"
   },
   "start_time": "2022-01-20T11:12:55.489185",
   "version": "2.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}